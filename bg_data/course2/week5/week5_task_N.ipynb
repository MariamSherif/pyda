{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "TASK1 = False\n",
    "TASK2 = False\n",
    "TASK3 = False\n",
    "TASK4 = False\n",
    "TASK5 = True\n",
    "TASK6 = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to\n",
      "      ____              __\n",
      "     / __/__  ___ _____/ /__\n",
      "    _\\ \\/ _ \\/ _ `/ __/  '_/\n",
      "   /__ / .__/\\_,_/_/ /_/\\_\\   version 2.1.1\n",
      "      /_/\n",
      "\n",
      "Using Python version 2.7.12 (default, Nov 19 2016 06:48:10)\n",
      "SparkSession available as 'spark'.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "execfile(os.path.join(os.environ[\"SPARK_HOME\"], 'python/pyspark/shell.py'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data description (DataFrames in parquet format)\n",
    "\n",
    "Location - `/data/sample264`\n",
    "\n",
    "Fields: `trackId`, `userId`, `timestamp`, `artistId`\n",
    "\n",
    "- `trackId` - `id` of the track\n",
    "- `userId` - `id` of the user\n",
    "- `artistId` - `id` of the artist\n",
    "- `timestamp` - `timestamp` of the moment the user starts listening to a track\n",
    "\n",
    "Location - `/data/meta`\n",
    "\n",
    "Fields: `type`, `Name`, `Artist`, `Id`\n",
    "\n",
    "- `Type` could be “track” or “artist”\n",
    "- `Name` is the title of the track if the type == “track” and the name of the musician or group if the type == “artist”.\n",
    "- `Artist` states for the creator of the track in case the type == “track” and for the name of the musician or group in case the type == “artist”.\n",
    "- `Id` - id of the item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "sparkSession = SparkSession.builder.enableHiveSupport().master(\"local [2]\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = sparkSession.read.parquet(\"/data/sample264\")\n",
    "meta = sparkSession.read.parquet(\"/data/meta\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization could be done by next function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Window\n",
    "from pyspark.sql.functions import row_number, sum\n",
    "\n",
    "def norm(df, key1, key2, field, n): \n",
    "    \n",
    "    window = Window.partitionBy(key1).orderBy(col(field).desc())\n",
    "        \n",
    "    topsDF = df.withColumn(\"row_number\", row_number().over(window)) \\\n",
    "        .filter(col(\"row_number\") <= n) \\\n",
    "        .drop(col(\"row_number\")) \n",
    "        \n",
    "    tmpDF = topsDF.groupBy(col(key1)).agg(col(key1), sum(col(field)).alias(\"sum_\" + field))\n",
    "   \n",
    "    normalizedDF = topsDF.join(tmpDF, key1, \"inner\") \\\n",
    "        .withColumn(\"norm_\" + field, col(field) / col(\"sum_\" + field)) \\\n",
    "        .cache()\n",
    "\n",
    "    return normalizedDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Window\n",
    "from pyspark.sql.functions import col, rank\n",
    "\n",
    "# userTrack = data.groupBy(col(\"userId\"), col(\"trackId\")).count()\n",
    "\n",
    "# userTrackNorm = norm(userTrack, \"userId\", \"trackId\", \"count\", 1000) \\\n",
    "#         .withColumn(\"id\", col(\"userId\")) \\\n",
    "#         .withColumn(\"id2\", col(\"trackId\")) \\\n",
    "#         .withColumn(\"norm_count\", col(\"norm_count\") * 0.5) \\\n",
    "#         .select(col(\"id\"), col(\"id2\"), col(\"norm_count\"))     \n",
    "\n",
    "# window = Window.orderBy(col(\"norm_count\"))\n",
    "    \n",
    "# userTrackList = userTrackNorm.withColumn(\"position\", rank().over(window))\\\n",
    "#     .filter(col(\"position\") < 50)\\\n",
    "#     .orderBy(col(\"id\"), col(\"id2\"))\\\n",
    "#     .select(col(\"id\"), col(\"id2\"))\\\n",
    "#     .take(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for val in userTrackList:\n",
    "#     print \"%s %s\" % val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import desc, asc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_result(df, task):\n",
    "    if not task:\n",
    "        return\n",
    "\n",
    "    window = Window.orderBy(desc('norm_count'))\n",
    "\n",
    "    result = (\n",
    "        df.withColumn('position', rank().over(window))\n",
    "        .filter(col('position') < 50)\n",
    "        .orderBy(asc('id1'), asc('id2'))\n",
    "        .select(col('id1'), col('id2'))\n",
    "    )\n",
    "\n",
    "    for row in result.take(40):\n",
    "        print '{r.id1} {r.id2}'.format(r=row)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Graph based Music Recommender. Task 1\n",
    "\n",
    "Build the edges of the type “track-track”. To do it you will need to count the collaborative similarity between all the tracks: if a user has listened To the tracks A and B together in THE limited time interval (equal to 7 minutes), then you should add 1 to the weight of the edge from vertex A to vertex B. For each track choose top 40 tracks similar to the initial one and normalize weights of its edges (divide the weight of each edge on a summary of weights of all edges).\n",
    "\n",
    "Sort the resulting Data Frame in ascending order by the column norm_count, take top 40 rows, select only the columns “id1”, “id2”, sort them in descending order this time first by “id1”, then by “id2” and print the columns “id1”, “id2” of the resulting dataframe.Example:\n",
    "\n",
    "```\n",
    "54719\t767867\n",
    "54719\t767866\n",
    "50787\t327676\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "_For all tasks use the same ipython notebook, each task should be the continuation of the previous._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "TIME_DELTA = 60 * 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1 = data.alias('d1')\n",
    "data_2 = data.alias('d2')\n",
    "\n",
    "cond = (\n",
    "    (col('d1.userId') == col('d2.userId'))\n",
    "    & (col('d1.timestamp') < col('d2.timestamp'))\n",
    "    & (col('d1.timestamp') + TIME_DELTA >= col('d2.timestamp'))\n",
    "    & (col('d1.trackId') != col('d2.trackId'))\n",
    ")\n",
    "\n",
    "djoin = (\n",
    "#     data_1.crossJoin(data_2)\n",
    "    data_1.join(data_2, cond, 'left_outer')\n",
    "#     .filter(cond)\n",
    "    .select(col('d1.trackId').alias('id1'), col('d2.trackId').alias('id2'))\n",
    "    .dropna()\n",
    "    .groupBy(col('id1'), col('id2'))\n",
    "    .count()\n",
    ")\n",
    "\n",
    "track_track = (\n",
    "    norm(djoin, 'id1', 'id2', 'count', 40)\n",
    "    .select(col('id1'), col('id2'), col('norm_count'))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print_result(track_track, TASK1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph based Music Recommender. Task 2\n",
    "\n",
    "Build the edges of the type “user-track”. Take the amount of times the track was listened by all users as the weight of the edge from the artist’s vertex to the track’s vertex. For each user take top-1000 and normalize them.\n",
    "\n",
    "Sort the resulting Data Frame in ascending order by the column norm_count, take top 40 rows, select only the columns “id1”, “id2”, sort them in descending order this time first by “id1”, then by “id2” and print the columns “id1”, “id2” of the resulting dataframe.\n",
    "\n",
    "Example:\n",
    "\n",
    "```\n",
    "54719\t767867\n",
    "54719\t767866\n",
    "50787\t327676\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_track = (\n",
    "    norm(data.groupBy('userId', 'trackId').count(), 'userId', 'trackId', 'count', 1000)\n",
    "    .withColumn('id1', col('userId'))\n",
    "    .withColumn('id2', col('trackId'))\n",
    "    .select(col('id1'), col('id2'), col('norm_count'))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print_result(user_track, TASK2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph based Music Recommender. Task 3\n",
    "\n",
    "Build the edges of the type “user-artist”. Take the amount of times the user has listened to the artist’s tracks as the weight of the edge from the user’s vertex to the artist’s vertex. For each user take top-100 artists and normalize weights.\n",
    "\n",
    "Sort the resulting Data Frame in ascending order by the column norm_count, take top 40 rows, select only the columns “id1”, “id2”, sort them in descending order this time first by “id1”, then by “id2” and print the columns “id1”, “id2” of the resulting dataframe.\n",
    "\n",
    "Example:\n",
    "\n",
    "```\n",
    "54719\t767867\n",
    "54719\t767866\n",
    "50787\t327676\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_artist = (\n",
    "    norm(data.groupBy('userId', 'artistId').count(), 'userId', 'artistId', 'count', 100)\n",
    "    .withColumn('id1', col('userId'))\n",
    "    .withColumn('id2', col('artistId'))\n",
    "    .select(col('id1'), col('id2'), col('norm_count'))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_result(user_artist, TASK3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph based Music Recommender. Task 4\n",
    "\n",
    "Build the edges of the type “artist-track”. Take the amount of times the track HAS BEEN listened by all users as the weight of the edge from the artist’s vertex to the track’s vertex. For each artist take top-100 tracks and normalize weights.\n",
    "\n",
    "Sort the resulting Data Frame in ascending order by the column norm_count (the column with normalized weights), take top 40 rows, select only the columns “id1”, “id2”, sort them in descending order this time first by “id1”, then by “id2” and print the columns “id1”, “id2” of the resulting dataframe.\n",
    "\n",
    "Example:\n",
    "```\n",
    "54719\t767867\n",
    "54719\t767866\n",
    "50787\t327676\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "artist_track = (\n",
    "    norm(data.groupBy('artistId', 'trackId').count(), 'artistId', 'trackId', 'count', 100)\n",
    "    .withColumn('id1', col('artistId'))\n",
    "    .withColumn('id2', col('trackId'))\n",
    "    .select(col('id1'), col('id2'), col('norm_count'))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_result(artist_track, TASK4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph based Music Recommender. Task 5\n",
    "\n",
    "Construct balancing function where the edges of the type “user-track” and the edges of the type “user-artist” influence the final recommendations equally.\n",
    "\n",
    "For the user with Id 776748 find all the tracks and artists connected to him. Sort founded items first by artist then by name in ascending order, leave only columns ”Artist” and “Name” and print top-40\n",
    "\n",
    "Example:\n",
    "\n",
    "```\n",
    "Artist: Green Day 21 Guns\n",
    "Artist: Green Day\n",
    "Artist: Green Day\n",
    "Artist: Green Day Kill The DJ\n",
    "Artist: Iggy Pop\n",
    "Artist: Iggy Pop\n",
    "Artist: Iggy Pop Sunday\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artist: 3 Doors Down Kryptonite\n",
      "Artist: 311 Beautiful disaster\n",
      "Artist: Blur Girls and Boys\n",
      "Artist: Clawfinger Nothing Going On\n",
      "Artist: Clawfinger Nothing Going On\n",
      "Artist: Disturbed The Vengeful One\n",
      "Artist: Gotthard Eagle\n",
      "Artist: Green Day 21 Guns\n",
      "Artist: Green Day 21 Guns\n",
      "Artist: Green Day Kill The DJ\n",
      "Artist: Green Day Kill The DJ\n",
      "Artist: Green Day Kill The DJ\n",
      "Artist: Iggy Pop Sunday\n",
      "Artist: Korn Here To Stay\n",
      "Artist: Linkin Park In The End\n",
      "Artist: Linkin Park Numb\n",
      "Artist: Lordi Hard Rock Hallelujah\n",
      "Artist: Nickelback She Keeps Me Up\n",
      "Artist: Nomy Cocaine\n",
      "Artist: Papa Roach Getting Away With Murder\n",
      "Artist: Rise Against Prayer Of The Refugee\n",
      "Artist: Serj Tankian Sky is Over\n",
      "Artist: Slipknot Wait And Bleed\n",
      "Artist: The Offspring Come Out and Play\n",
      "Artist: The Offspring Come Out and Play\n",
      "Artist: Thousand Foot Krutch Take It Out On Me\n",
      "Artist: Three Days Grace I Hate Everything About You\n"
     ]
    }
   ],
   "source": [
    "result = (\n",
    "    data.filter(col('userId') == 776748)\n",
    "    .join(meta, (col('trackId') == col('Id')), 'left_outer')\n",
    "    .orderBy(asc('Artist'), asc('Name'))\n",
    "    .select('Artist', 'Name')\n",
    ")\n",
    "\n",
    "if TASK5:\n",
    "    for row in result.take(40):\n",
    "        print '{r.Artist} {r.Name}'.format(r=row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph based Music Recommender. Task 6\n",
    "\n",
    "For the user with Id 776748 print top-40 recommended tracks. Build music recommendations with the algorithm described in the lesson 3 of the fourth week. Initialize coordinates of vector x_0 corresponding to the user’s vertex and vertices from step 7 with ones and all other coordinates with zeros. Do 5 iterations.\n",
    "\n",
    "You should receive a table with 3 collumns: “name”, “artist” and “rank”. Sort the resulting dataframe in descending order by “rank”, select top 40 recommended tracks, select only the columns “name”, “artist” and “rank”, leave 5 digits after the decimal point in “rank” and print the resulting dataframe.\n",
    "\n",
    "Example:\n",
    "\n",
    "```\n",
    "Smells Like Teen Spirit Artist: Nirvana 0.09401\n",
    "Whispers In The Dark Artist: Skillet 0.07914\n",
    "Kisses Back Artist: Matthew Koma 0.07876\n",
    "Attention Artist: Charlie Puth 0.07851\n",
    "Nothing Else Matters Artist: Metallica 0.07674\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
