{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to\n",
      "      ____              __\n",
      "     / __/__  ___ _____/ /__\n",
      "    _\\ \\/ _ \\/ _ `/ __/  '_/\n",
      "   /__ / .__/\\_,_/_/ /_/\\_\\   version 2.1.1\n",
      "      /_/\n",
      "\n",
      "Using Python version 2.7.12 (default, Nov 19 2016 06:48:10)\n",
      "SparkSession available as 'spark'.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "execfile(os.path.join(os.environ[\"SPARK_HOME\"], 'python/pyspark/shell.py'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data description (DataFrames in parquet format)\n",
    "\n",
    "Location - `/data/sample264`\n",
    "\n",
    "Fields: `trackId`, `userId`, `timestamp`, `artistId`\n",
    "\n",
    "- `trackId` - `id` of the track\n",
    "- `userId` - `id` of the user\n",
    "- `artistId` - `id` of the artist\n",
    "- `timestamp` - `timestamp` of the moment the user starts listening to a track\n",
    "\n",
    "Location - `/data/meta`\n",
    "\n",
    "Fields: `type`, `Name`, `Artist`, `Id`\n",
    "\n",
    "- `Type` could be “track” or “artist”\n",
    "- `Name` is the title of the track if the type == “track” and the name of the musician or group if the type == “artist”.\n",
    "- `Artist` states for the creator of the track in case the type == “track” and for the name of the musician or group in case the type == “artist”.\n",
    "- `Id` - id of the item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "sparkSession = SparkSession.builder.enableHiveSupport().master(\"local [2]\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = sparkSession.read.parquet(\"/data/sample264\")\n",
    "meta = sparkSession.read.parquet(\"/data/meta\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization could be done by next function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Window\n",
    "from pyspark.sql.functions import row_number, sum, desc, asc, udf\n",
    "from pyspark.sql import types\n",
    "\n",
    "\n",
    "def norm_pair(value, summ):\n",
    "    return value / summ if value != summ else 0.5\n",
    "udf_norm_pair = udf(norm_pair, types.FloatType())\n",
    "\n",
    "\n",
    "def norm(df, key1, key2, field, n): \n",
    "    \n",
    "    window = Window.partitionBy(key1).orderBy(col(field).desc())\n",
    "        \n",
    "    topsDF = (\n",
    "        df\n",
    "        .withColumn(\"row_number\", row_number().over(window))\n",
    "        .filter(col(\"row_number\") <= n)\n",
    "        .drop(col(\"row_number\")) \n",
    "    )\n",
    "        \n",
    "    tmpDF = topsDF.groupBy(col(key1)).agg(col(key1), sum(col(field)).alias(\"sum_\" + field))\n",
    "   \n",
    "    normalizedDF = (\n",
    "        topsDF\n",
    "        .join(tmpDF, key1, \"inner\")\n",
    "        .withColumn(\"norm_\" + field, udf_norm_pair(col(field), col(\"sum_\" + field)))\n",
    "        .cache()\n",
    "    )\n",
    "\n",
    "    return normalizedDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Window\n",
    "from pyspark.sql.functions import col, rank\n",
    "\n",
    "# userTrack = data.groupBy(col(\"userId\"), col(\"trackId\")).count()\n",
    "\n",
    "# userTrackNorm = (\n",
    "#     norm(userTrack, \"userId\", \"trackId\", \"count\", 1000)\n",
    "#     .withColumn(\"id\", col(\"userId\"))\n",
    "#     .withColumn(\"id2\", col(\"trackId\"))\n",
    "#     .withColumn(\"norm_count\", col(\"norm_count\") * 0.5)\n",
    "#     .select(col(\"id\"), col(\"id2\"), col(\"norm_count\"))\n",
    "# )\n",
    "\n",
    "# window = Window.orderBy(col(\"norm_count\"))\n",
    "    \n",
    "# userTrackList = (\n",
    "#     userTrackNorm.withColumn(\"position\", rank().over(window))\n",
    "#     .filter(col(\"position\") < 50)\n",
    "#     .orderBy(col(\"id\"), col(\"id2\"))\n",
    "#     .select(col(\"id\"), col(\"id2\"))\n",
    "#     .take(40)\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for val in userTrackList:\n",
    "#     print \"%s %s\" % val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Graph based Music Recommender. Task 1\n",
    "\n",
    "Build the edges of the type “track-track”. To do it you will need to count the collaborative similarity between all the tracks: if a user has listened To the tracks A and B together in THE limited time interval (equal to 7 minutes), then you should add 1 to the weight of the edge from vertex A to vertex B. For each track choose top 40 tracks similar to the initial one and normalize weights of its edges (divide the weight of each edge on a summary of weights of all edges).\n",
    "\n",
    "Sort the resulting Data Frame in ascending order by the column norm_count, take top 40 rows, select only the columns “id1”, “id2”, sort them in descending order this time first by “id1”, then by “id2” and print the columns “id1”, “id2” of the resulting dataframe.Example:\n",
    "\n",
    "```\n",
    "54719\t767867\n",
    "54719\t767866\n",
    "50787\t327676\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "_For all tasks use the same ipython notebook, each task should be the continuation of the previous._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "TIME_DELTA = 60 * 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1 = data.alias('d1')\n",
    "data_2 = data.alias('d2')\n",
    "\n",
    "cond = (\n",
    "    (col('d1.userId') == col('d2.userId'))\n",
    "    & (col('d1.timestamp') < col('d2.timestamp'))\n",
    "    & (col('d1.timestamp') + TIME_DELTA >= col('d2.timestamp'))\n",
    "    & (col('d1.trackId') != col('d2.trackId'))\n",
    ")\n",
    "\n",
    "djoin = (\n",
    "#     data_1.crossJoin(data_2)\n",
    "    data_1.join(data_2, cond, 'left_outer')\n",
    "#     .filter(cond)\n",
    "    .select(col('d1.trackId').alias('id1'), col('d2.trackId').alias('id2'))\n",
    "    .dropna()\n",
    "    .groupBy(col('id1'), col('id2'))\n",
    "    .count()\n",
    ")\n",
    "\n",
    "track_track = (\n",
    "    norm(djoin, 'id1', 'id2', 'count', 40)\n",
    "    .select(col('id1'), col('id2'), col('norm_count'))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "798256 923706\n",
      "798258 808254\n",
      "798302 836228\n",
      "798322 876562\n",
      "798331 827364\n",
      "798335 840741\n",
      "798376 888871\n",
      "798379 812055\n",
      "798398 926302\n",
      "798403 868805\n",
      "798405 867217\n",
      "798426 910880\n",
      "798447 832635\n",
      "798457 918918\n",
      "798471 801831\n",
      "798474 963162\n",
      "798475 827475\n",
      "798505 905671\n",
      "798508 810743\n",
      "798516 860347\n",
      "798526 937573\n",
      "798542 946408\n",
      "798544 841232\n",
      "798550 936295\n",
      "798552 830267\n",
      "798618 930224\n",
      "798667 874844\n",
      "798682 934393\n",
      "798704 937570\n",
      "798707 839389\n",
      "798720 958333\n",
      "798725 933147\n",
      "798731 853117\n",
      "798782 956938\n",
      "798801 950802\n",
      "798820 890393\n",
      "798821 883244\n",
      "798827 908022\n",
      "798851 801321\n",
      "798978 854212\n"
     ]
    }
   ],
   "source": [
    "window = Window.orderBy(desc('norm_count'), asc('id1'), asc('id2'))\n",
    "\n",
    "result = (\n",
    "    track_track\n",
    "    .withColumn('position', rank().over(window))\n",
    "    .filter(col('position') <= 40)\n",
    "    .orderBy(asc('id1'), asc('id2'))\n",
    "    .select(col('id1'), col('id2'))\n",
    ")\n",
    "\n",
    "for row in result.take(40):\n",
    "    print '{r.id1} {r.id2}'.format(r=row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph based Music Recommender. Task 2\n",
    "\n",
    "Build the edges of the type “user-track”. Take the amount of times the track was listened by all users as the weight of the edge from the artist’s vertex to the track’s vertex. For each user take top-1000 and normalize them.\n",
    "\n",
    "Sort the resulting Data Frame in ascending order by the column norm_count, take top 40 rows, select only the columns “id1”, “id2”, sort them in descending order this time first by “id1”, then by “id2” and print the columns “id1”, “id2” of the resulting dataframe.\n",
    "\n",
    "Example:\n",
    "\n",
    "```\n",
    "54719\t767867\n",
    "54719\t767866\n",
    "50787\t327676\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_track = (\n",
    "    norm(data.groupBy('userId', 'trackId').count(), 'userId', 'trackId', 'count', 1000)\n",
    "    .withColumn('id1', col('userId'))\n",
    "    .withColumn('id2', col('trackId'))\n",
    "    .select(col('id1'), col('id2'), col('norm_count'))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66 965774\n",
      "116 867268\n",
      "128 852564\n",
      "131 880170\n",
      "195 946408\n",
      "215 860111\n",
      "235 897176\n",
      "300 857973\n",
      "321 915545\n",
      "328 943482\n",
      "333 818202\n",
      "346 864911\n",
      "356 961308\n",
      "428 943572\n",
      "431 902497\n",
      "445 831381\n",
      "488 841340\n",
      "542 815388\n",
      "617 946395\n",
      "649 901672\n",
      "658 937522\n",
      "662 881433\n",
      "698 935934\n",
      "708 952432\n",
      "746 879259\n",
      "747 879259\n",
      "776 946408\n",
      "784 806468\n",
      "806 866581\n",
      "811 948017\n",
      "837 799685\n",
      "901 871513\n",
      "923 879322\n",
      "934 940714\n",
      "957 945183\n",
      "989 878364\n",
      "999 967768\n",
      "1006 962774\n",
      "1049 849484\n",
      "1057 920458\n"
     ]
    }
   ],
   "source": [
    "window = Window.orderBy(desc('norm_count'), asc('id1'), asc('id2'))\n",
    "\n",
    "result = (\n",
    "    user_track\n",
    "    .withColumn('position', rank().over(window))\n",
    "    .filter(col('position') <= 40)\n",
    "    .orderBy(asc('id1'), asc('id2'))\n",
    "    .select(col('id1'), col('id2'))\n",
    ")\n",
    "\n",
    "for row in result.take(40):\n",
    "    print '{r.id1} {r.id2}'.format(r=row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph based Music Recommender. Task 3\n",
    "\n",
    "Build the edges of the type “user-artist”. Take the amount of times the user has listened to the artist’s tracks as the weight of the edge from the user’s vertex to the artist’s vertex. For each user take top-100 artists and normalize weights.\n",
    "\n",
    "Sort the resulting Data Frame in ascending order by the column norm_count, take top 40 rows, select only the columns “id1”, “id2”, sort them in descending order this time first by “id1”, then by “id2” and print the columns “id1”, “id2” of the resulting dataframe.\n",
    "\n",
    "Example:\n",
    "\n",
    "```\n",
    "54719\t767867\n",
    "54719\t767866\n",
    "50787\t327676\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_artist = (\n",
    "    norm(data.groupBy('userId', 'artistId').count(), 'userId', 'artistId', 'count', 100)\n",
    "    .withColumn('id1', col('userId'))\n",
    "    .withColumn('id2', col('artistId'))\n",
    "    .select(col('id1'), col('id2'), col('norm_count'))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66 993426\n",
      "116 974937\n",
      "128 1003021\n",
      "131 983068\n",
      "195 997265\n",
      "215 991696\n",
      "235 990642\n",
      "288 1000564\n",
      "300 1003362\n",
      "321 986172\n",
      "328 967986\n",
      "333 1000416\n",
      "346 982037\n",
      "356 974846\n",
      "374 1003167\n",
      "428 993161\n",
      "431 969340\n",
      "445 970387\n",
      "488 970525\n",
      "542 969751\n",
      "612 987351\n",
      "617 970240\n",
      "649 973851\n",
      "658 973232\n",
      "662 975279\n",
      "698 995788\n",
      "708 968848\n",
      "746 972032\n",
      "747 972032\n",
      "776 997265\n",
      "784 969853\n",
      "806 995126\n",
      "811 996436\n",
      "837 989262\n",
      "901 988199\n",
      "923 977066\n",
      "934 990860\n",
      "957 991171\n",
      "989 975339\n",
      "999 968823\n"
     ]
    }
   ],
   "source": [
    "window = Window.orderBy(desc('norm_count'), asc('id1'), asc('id2'))\n",
    "\n",
    "result = (\n",
    "    user_artist\n",
    "    .withColumn('position', rank().over(window))\n",
    "    .filter(col('position') <= 40)\n",
    "    .orderBy(asc('id1'), asc('id2'))\n",
    "    .select(col('id1'), col('id2'))\n",
    ")\n",
    "\n",
    "for row in result.take(40):\n",
    "    print '{r.id1} {r.id2}'.format(r=row)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
