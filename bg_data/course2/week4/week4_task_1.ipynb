{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Counting number of the mutual friends\n",
    "\n",
    "For each user having ID in the column userId count the amount of his / her common friends with each other user having ID in the column userId.\n",
    "\n",
    "Print 49 pairs of the users having the largest amount of common friends, ordered in descending order first by the common friends count , then by id of user1 and finally by id of user 2.\n",
    "\n",
    "To solve this task use the algorithm described in the last video of lesson 1.\n",
    "\n",
    "The sample dataset is located at `/data/graphDFSample`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to\n",
      "      ____              __\n",
      "     / __/__  ___ _____/ /__\n",
      "    _\\ \\/ _ \\/ _ `/ __/  '_/\n",
      "   /__ / .__/\\_,_/_/ /_/\\_\\   version 2.1.1\n",
      "      /_/\n",
      "\n",
      "Using Python version 2.7.12 (default, Nov 19 2016 06:48:10)\n",
      "SparkSession available as 'spark'.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "execfile(os.path.join(os.environ[\"SPARK_HOME\"], 'python/pyspark/shell.py'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "sparkSession = SparkSession.builder.enableHiveSupport().master(\"local [2]\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphPath = \"/data/graphDFSample\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import explode, collect_list, size, col, asc, desc, sort_array\n",
    "from pyspark.sql import Window\n",
    "\n",
    "reversedGraph = (\n",
    "    sparkSession.read.parquet(graphPath)\n",
    "    .withColumn(\"friend\", explode('friends'))\n",
    "    .groupBy(\"friend\")\n",
    "    .agg(collect_list(\"user\").alias(\"users\"))\n",
    "    .withColumn(\"users_size\", size(\"users\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjacency_lists = reversedGraph.filter(col('users_size') > 1).select(sort_array('users').alias('adj'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql import types\n",
    "\n",
    "\n",
    "def comb(array):\n",
    "    return list(combinations(array, 2))\n",
    "\n",
    "\n",
    "schema = types.ArrayType(types.IntegerType())\n",
    "\n",
    "udf_comb = udf(comb, types.ArrayType(schema))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_users = (\n",
    "    adjacency_lists\n",
    "        .withColumn('udf_comb', udf_comb(col('adj')))\n",
    "        .select(explode('udf_comb'))\n",
    "        .withColumn('a', col('col').getItem(0))\n",
    "        .withColumn('b', col('col').getItem(1))\n",
    "        .groupBy('a', 'b')\n",
    "        .count()\n",
    "        .orderBy(desc('count'), desc('a'), desc('b'))\n",
    ")\n",
    "# combined_users.cache()\n",
    "# combined_users.show(49)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3206 27967558 42973992\n",
      "3130 20158643 42973992\n",
      "3066 22582764 42973992\n",
      "3044 21864412 51640390\n",
      "3021 17139850 51640390\n",
      "3010 14985079 51640390\n",
      "2970 17139850 21864412\n",
      "2913 20158643 27967558\n",
      "2903 22280814 51151280\n",
      "2870 23848749 51640390\n",
      "2855 20158643 22582764\n",
      "2849 20158643 44996025\n",
      "2846 22280814 42973992\n",
      "2784 21864412 23848749\n",
      "2779 31964081 51640390\n",
      "2776 39205988 51640390\n",
      "2754 17139850 23848749\n",
      "2749 22582764 27967558\n",
      "2728 50561859 51640390\n",
      "2724 15485897 51640390\n",
      "2700 28135661 42973992\n",
      "2655 22280814 27967558\n",
      "2653 42973992 43548989\n",
      "2639 26755857 51640390\n",
      "2621 14635589 51640390\n",
      "2608 15485897 17139850\n",
      "2606 17139850 26755857\n",
      "2601 21864412 39205988\n",
      "2600 8406745 51640390\n",
      "2599 37735419 51640390\n",
      "2597 20158643 28135661\n",
      "2585 40003405 42973992\n",
      "2585 21864412 31964081\n",
      "2581 27967558 43548989\n",
      "2579 23848749 31964081\n",
      "2578 27967558 28135661\n",
      "2578 15485897 21864412\n",
      "2577 42973992 64755069\n",
      "2574 51151280 57077210\n",
      "2573 20158643 43548989\n",
      "2566 21864412 26755857\n",
      "2564 22280814 64755069\n",
      "2561 42973992 44996025\n",
      "2556 17139850 39205988\n",
      "2543 23848749 39205988\n",
      "2521 17139850 31964081\n",
      "2515 27967558 44996025\n",
      "2506 41629539 51640390\n",
      "2505 51151280 64755069\n"
     ]
    }
   ],
   "source": [
    "for row in combined_users.take(49):\n",
    "    print row['count'], row['a'], row['b']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
