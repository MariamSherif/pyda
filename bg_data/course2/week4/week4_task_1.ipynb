{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Counting number of the mutual friends\n",
    "\n",
    "For each user having ID in the column userId count the amount of his / her common friends with each other user having ID in the column userId.\n",
    "\n",
    "Print 49 pairs of the users having the largest amount of common friends, ordered in descending order first by the common friends count , then by id of user1 and finally by id of user 2.\n",
    "\n",
    "To solve this task use the algorithm described in the last video of lesson 1.\n",
    "\n",
    "The sample dataset is located at `/data/graphDFSample`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to\n",
      "      ____              __\n",
      "     / __/__  ___ _____/ /__\n",
      "    _\\ \\/ _ \\/ _ `/ __/  '_/\n",
      "   /__ / .__/\\_,_/_/ /_/\\_\\   version 2.1.1\n",
      "      /_/\n",
      "\n",
      "Using Python version 2.7.12 (default, Nov 19 2016 06:48:10)\n",
      "SparkSession available as 'spark'.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "execfile(os.path.join(os.environ[\"SPARK_HOME\"], 'python/pyspark/shell.py'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "sparkSession = SparkSession.builder.enableHiveSupport().master(\"local [2]\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphPath = \"/data/graphDFSample\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import explode, collect_list, size, col, asc, desc, sort_array\n",
    "from pyspark.sql import Window\n",
    "\n",
    "reversedGraph = (\n",
    "    sparkSession.read.parquet(graphPath)\n",
    "    .withColumn(\"friend\", explode('friends'))\n",
    "    .groupBy(\"friend\")\n",
    "    .agg(collect_list(\"user\").alias(\"users\"))\n",
    "    .withColumn(\"users_size\", size(\"users\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjacency_lists = reversedGraph.filter(col('users_size') > 1).select(sort_array('users').alias('adj'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql import types\n",
    "\n",
    "\n",
    "def comb(array):\n",
    "    return list(combinations(array, 2))\n",
    "\n",
    "\n",
    "schema = types.ArrayType(types.IntegerType())\n",
    "\n",
    "udf_comb = udf(comb, types.ArrayType(schema))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_users = (\n",
    "    adjacency_lists\n",
    "        .withColumn('udf_comb', udf_comb(col('adj')))\n",
    "        .select(explode('udf_comb'))\n",
    "        .withColumn('a', col('col').getItem(0))\n",
    "        .withColumn('b', col('col').getItem(1))\n",
    "        .groupBy('a', 'b')\n",
    "        .count()\n",
    "        .orderBy(desc('count'), asc('a'), asc('b'))\n",
    ")\n",
    "# combined_users.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined_users.show(49)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in combined_users.take(49):\n",
    "    print row['a'], row['b'], row['count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combined_users.take(1)[0]['count']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
