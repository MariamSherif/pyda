{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Programming Assignment\n",
    "## Готовим LDA по рецептам"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как вы уже знаете, в тематическом моделировании делается предположение о том, что для определения тематики порядок слов в документе не важен; об этом гласит гипотеза <<мешка слов>>. Сегодня мы будем работать с несколько нестандартной для тематического моделирования коллекцией, которую можно назвать <<мешком ингредиентов>>, потому что на состоит из рецептов блюд разных кухонь. Тематические модели ищут слова, которые часто вместе встречаются в документах, и составляют из них темы. Мы попробуем применить эту идею к рецептам и найти кулинарные <<темы>>. Эта коллекция хороша тем, что не требует предобработки. Кроме того, эта задача достаточно наглядно иллюстрирует принцип работы тематических моделей.\n",
    "\n",
    "Для выполнения заданий, помимо часто используемых в курсе библиотек, потребуются модули json и gensim. Первый входит в дистрибутив Anaconda, второй можно поставить командой \n",
    "\n",
    "pip install gensim\n",
    "\n",
    "или\n",
    "\n",
    "conda install gensim\n",
    "\n",
    "Построение модели занимает некоторое время. На ноутбуке с процессором Intel Core i7 и тактовой частотой 2400 МГц на построение одной модели уходит менее 10 минут."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загрузка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Коллекция дана в json-формате: для каждого рецепта известны его id, кухня (\"cuisine\") и список ингредиентов, в него входящих. Загрузить данные можно с помощью модуля json (он входит в дистрибутив Anaconda):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"recipes.json\") as f:\n",
    "    recipes = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'cuisine': u'greek', u'id': 10259, u'ingredients': [u'romaine lettuce', u'black olives', u'grape tomatoes', u'garlic', u'pepper', u'purple onion', u'seasoning', u'garbanzo beans', u'feta cheese crumbles']}\n"
     ]
    }
   ],
   "source": [
    "print recipes[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Составление корпуса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from gensim import corpora, models\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наша коллекция небольшая и влезает в оперативную память. Gensim может работать с такими данными и не требует их сохранения на диск в специальном формате. Для этого коллекция должна быть представлена в виде списка списков, каждый внутренний список соответствует отдельному документу и состоит из его слов. Пример коллекции из двух документов: \n",
    "\n",
    "[[\"hello\", \"world\"], [\"programming\", \"in\", \"python\"]]\n",
    "\n",
    "Преобразуем наши данные в такой формат, а затем создадим объекты corpus и dictionary, с которыми будет работать модель."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "texts = [recipe[\"ingredients\"] for recipe in recipes]\n",
    "dictionary = corpora.Dictionary(texts)   # составляем словарь\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]  # составляем корпус документов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'romaine lettuce', u'black olives', u'grape tomatoes', u'garlic', u'pepper', u'purple onion', u'seasoning', u'garbanzo beans', u'feta cheese crumbles']\n",
      "[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1)]\n"
     ]
    }
   ],
   "source": [
    "print texts[0]\n",
    "print corpus[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У объекта dictionary есть две полезных переменных: dictionary.id2token и dictionary.token2id; эти словари позволяют находить соответствие между ингредиентами и их индексами."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучение модели\n",
    "Вам может понадобиться [документация](https://radimrehurek.com/gensim/models/ldamodel.html) LDA в gensim."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Задание 1.__ Обучите модель LDA с 40 темами, установив количество проходов по коллекции 5 и оставив остальные параметры по умолчанию. Затем вызовите метод модели show_topics, указав количество тем 40 и количество токенов 10, и сохраните результат (топы ингредиентов в темах) в отдельную переменную. Если при вызове метода show_topics указать параметр formatted=True, то топы ингредиентов будет удобно выводить на печать, если formatted=False, будет удобно работать со списком программно. Выведите топы на печать, рассмотрите темы, а затем ответьте на вопрос:\n",
    "\n",
    "Сколько раз ингредиенты \"salt\", \"sugar\", \"water\", \"mushrooms\", \"chicken\", \"eggs\" встретились среди топов-10 всех 40 тем? При ответе __не нужно__ учитывать составные ингредиенты, например, \"hot water\".\n",
    "\n",
    "Передайте 6 чисел в функцию save_answers1 и загрузите сгенерированный файл в форму.\n",
    "\n",
    "У gensim нет возможности фиксировать случайное приближение через параметры метода, но библиотека использует numpy для инициализации матриц. Поэтому, по утверждению автора библиотеки, фиксировать случайное приближение нужно командой, которая написана в следующей ячейке. __Перед строкой кода с построением модели обязательно вставляйте указанную строку фиксации random.seed.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gensim.models.ldamodel:no word id mapping provided; initializing from corpus, assuming identity\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(76543)\n",
    "# здесь код для построения модели:\n",
    "lda = models.LdaModel(corpus, num_topics=40, passes=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "topics = lda.show_topics(num_topics=40, num_words=10, formatted=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  [('116', 0.08893168359335854),\n",
       "   ('17', 0.083023313122701475),\n",
       "   ('100', 0.079694482383533452),\n",
       "   ('54', 0.0680566977323325),\n",
       "   ('279', 0.065740286303090784),\n",
       "   ('307', 0.036603425389428054),\n",
       "   ('119', 0.036151588839948144),\n",
       "   ('38', 0.034352059579260519),\n",
       "   ('12', 0.032028828039852998),\n",
       "   ('29', 0.032026346546356513)]),\n",
       " (1,\n",
       "  [('195', 0.084685047417615719),\n",
       "   ('45', 0.059477185904889492),\n",
       "   ('275', 0.056696097267259354),\n",
       "   ('178', 0.056348277206384155),\n",
       "   ('124', 0.046496298177981524),\n",
       "   ('958', 0.039387696216511309),\n",
       "   ('705', 0.033278198173197236),\n",
       "   ('29', 0.032572054032539745),\n",
       "   ('219', 0.02946783427136733),\n",
       "   ('1493', 0.027719405825683066)]),\n",
       " (2,\n",
       "  [('350', 0.065793037833935572),\n",
       "   ('770', 0.058809351108989147),\n",
       "   ('830', 0.041491648463130429),\n",
       "   ('1338', 0.041121673243871608),\n",
       "   ('480', 0.039788950941651476),\n",
       "   ('3', 0.039484338255465386),\n",
       "   ('1637', 0.035205806717994427),\n",
       "   ('816', 0.030809498417447782),\n",
       "   ('806', 0.029339305231140551),\n",
       "   ('117', 0.029082580099877169)]),\n",
       " (3,\n",
       "  [('207', 0.13264991233166151),\n",
       "   ('41', 0.12392896234858589),\n",
       "   ('17', 0.063326733043941125),\n",
       "   ('383', 0.059179676560327313),\n",
       "   ('45', 0.042020178848626258),\n",
       "   ('425', 0.038367186668332623),\n",
       "   ('0', 0.034463196802498951),\n",
       "   ('397', 0.033048438299776911),\n",
       "   ('77', 0.031199828274823368),\n",
       "   ('792', 0.026229917191349733)]),\n",
       " (4,\n",
       "  [('200', 0.062137194484359899),\n",
       "   ('20', 0.057518365294650431),\n",
       "   ('39', 0.055607203040325813),\n",
       "   ('17', 0.053129801326957084),\n",
       "   ('183', 0.044357251694682465),\n",
       "   ('45', 0.035222635468300588),\n",
       "   ('348', 0.034801505725109289),\n",
       "   ('236', 0.03199020314811063),\n",
       "   ('216', 0.027267339886862429),\n",
       "   ('12', 0.027067277200853602)]),\n",
       " (5,\n",
       "  [('46', 0.076627285122494199),\n",
       "   ('17', 0.052261476695032109),\n",
       "   ('113', 0.048314322271712437),\n",
       "   ('45', 0.036445389125942904),\n",
       "   ('54', 0.035941283188257629),\n",
       "   ('4', 0.033314493875509402),\n",
       "   ('183', 0.028238586829496485),\n",
       "   ('127', 0.025756401308228268),\n",
       "   ('39', 0.02293977686273951),\n",
       "   ('100', 0.022337497196979025)]),\n",
       " (6,\n",
       "  [('51', 0.10667595663455667),\n",
       "   ('366', 0.087421774887951789),\n",
       "   ('310', 0.056105924125548899),\n",
       "   ('541', 0.046776482531706465),\n",
       "   ('494', 0.046276683476044959),\n",
       "   ('387', 0.045913091159994153),\n",
       "   ('249', 0.043664170427418471),\n",
       "   ('52', 0.03118742081288901),\n",
       "   ('373', 0.030182049216845915),\n",
       "   ('511', 0.030117163634709381)]),\n",
       " (7,\n",
       "  [('557', 0.084742642422514003),\n",
       "   ('112', 0.080497578113583712),\n",
       "   ('76', 0.077370715659880906),\n",
       "   ('54', 0.073934264873813715),\n",
       "   ('358', 0.046646113791840429),\n",
       "   ('17', 0.039214680830128558),\n",
       "   ('190', 0.030897630465110175),\n",
       "   ('100', 0.029836911250445262),\n",
       "   ('141', 0.029530917231211342),\n",
       "   ('193', 0.02864503120588403)]),\n",
       " (8,\n",
       "  [('155', 0.087167378750824309),\n",
       "   ('23', 0.077098782201917557),\n",
       "   ('17', 0.067277135535202148),\n",
       "   ('29', 0.058749189922320338),\n",
       "   ('471', 0.050622406492365747),\n",
       "   ('456', 0.048994075835856951),\n",
       "   ('352', 0.045755197636105201),\n",
       "   ('1286', 0.035831587208417962),\n",
       "   ('1090', 0.029395533471377043),\n",
       "   ('1255', 0.023020562542490883)]),\n",
       " (9,\n",
       "  [('83', 0.078917014125290771),\n",
       "   ('45', 0.07272401577286422),\n",
       "   ('4', 0.060870846457765838),\n",
       "   ('478', 0.057305229057996281),\n",
       "   ('17', 0.052576199890923249),\n",
       "   ('321', 0.05043290807248195),\n",
       "   ('229', 0.04908031515736036),\n",
       "   ('230', 0.043086220699036691),\n",
       "   ('345', 0.040347252869254016),\n",
       "   ('54', 0.034981688994508701)]),\n",
       " (10,\n",
       "  [('313', 0.049367681116827954),\n",
       "   ('12', 0.048029125078342991),\n",
       "   ('21', 0.037340281661360532),\n",
       "   ('990', 0.036477703219749781),\n",
       "   ('114', 0.030782680251151686),\n",
       "   ('78', 0.029591436646871912),\n",
       "   ('514', 0.027102675306152648),\n",
       "   ('624', 0.02662087179123895),\n",
       "   ('204', 0.025770559902268717),\n",
       "   ('17', 0.024067311817708492)]),\n",
       " (11,\n",
       "  [('58', 0.066996273870029266),\n",
       "   ('17', 0.064211043652989852),\n",
       "   ('110', 0.05061887587346478),\n",
       "   ('74', 0.04214971834609723),\n",
       "   ('8', 0.034953554052417866),\n",
       "   ('4', 0.034417628909233201),\n",
       "   ('54', 0.032394638512492878),\n",
       "   ('111', 0.031557259666404186),\n",
       "   ('839', 0.030696574173231211),\n",
       "   ('108', 0.029169836782926374)]),\n",
       " (12,\n",
       "  [('536', 0.13387370070367385),\n",
       "   ('569', 0.07042634503602048),\n",
       "   ('1044', 0.045773470475447789),\n",
       "   ('530', 0.045341315625472368),\n",
       "   ('1743', 0.039782988887878803),\n",
       "   ('7', 0.039380622131585365),\n",
       "   ('876', 0.035210285179868503),\n",
       "   ('600', 0.03399716798286323),\n",
       "   ('1043', 0.030538503372421061),\n",
       "   ('564', 0.02744680848265205)]),\n",
       " (13,\n",
       "  [('272', 0.085502447593804945),\n",
       "   ('577', 0.0563216687559722),\n",
       "   ('246', 0.049190995951747044),\n",
       "   ('201', 0.048325541653898817),\n",
       "   ('33', 0.040649866957816312),\n",
       "   ('520', 0.039468024154463509),\n",
       "   ('231', 0.033862702745164494),\n",
       "   ('46', 0.031229330247281972),\n",
       "   ('71', 0.02574708676603827),\n",
       "   ('69', 0.023999503101898981)]),\n",
       " (14,\n",
       "  [('228', 0.11057378122584116),\n",
       "   ('128', 0.085889809769788841),\n",
       "   ('864', 0.058101769426575994),\n",
       "   ('431', 0.049503586868320452),\n",
       "   ('622', 0.045058371287366547),\n",
       "   ('819', 0.0369689265867073),\n",
       "   ('129', 0.032155649828819764),\n",
       "   ('48', 0.024232419993286628),\n",
       "   ('367', 0.02260354568906477),\n",
       "   ('143', 0.021670741100373835)]),\n",
       " (15,\n",
       "  [('318', 0.089901875182646793),\n",
       "   ('432', 0.071898066225266399),\n",
       "   ('205', 0.056970939038014624),\n",
       "   ('48', 0.044393889192308016),\n",
       "   ('243', 0.041122750693504857),\n",
       "   ('496', 0.032580500436037219),\n",
       "   ('756', 0.029463615896518056),\n",
       "   ('385', 0.02673348870566802),\n",
       "   ('1607', 0.02607419728372698),\n",
       "   ('835', 0.023535827999710109)]),\n",
       " (16,\n",
       "  [('79', 0.10083323829836822),\n",
       "   ('100', 0.059852691103642358),\n",
       "   ('54', 0.050279471669856315),\n",
       "   ('59', 0.046381772171346272),\n",
       "   ('250', 0.039457041002068961),\n",
       "   ('106', 0.038560812772401705),\n",
       "   ('17', 0.038080060156889327),\n",
       "   ('309', 0.036468942702369861),\n",
       "   ('251', 0.032168171728790607),\n",
       "   ('12', 0.029174154327681175)]),\n",
       " (17,\n",
       "  [('357', 0.14039473267660582),\n",
       "   ('237', 0.053520649826206461),\n",
       "   ('11', 0.047876444918555638),\n",
       "   ('242', 0.044859599676256863),\n",
       "   ('4', 0.03483908552759829),\n",
       "   ('678', 0.033375879670636849),\n",
       "   ('45', 0.033202434624157506),\n",
       "   ('1405', 0.024500029872723303),\n",
       "   ('1291', 0.024385440595203877),\n",
       "   ('17', 0.0196755431489056)]),\n",
       " (18,\n",
       "  [('17', 0.10286475889374329),\n",
       "   ('117', 0.090362466014752368),\n",
       "   ('13', 0.086572915929855138),\n",
       "   ('18', 0.08518924452520632),\n",
       "   ('21', 0.07002848634601011),\n",
       "   ('49', 0.054567443817826314),\n",
       "   ('48', 0.049774314966074228),\n",
       "   ('63', 0.039811370974946109),\n",
       "   ('311', 0.034297844284951015),\n",
       "   ('289', 0.030033979348320791)]),\n",
       " (19,\n",
       "  [('273', 0.13496195156332089),\n",
       "   ('556', 0.071171290698734915),\n",
       "   ('534', 0.064775826950889043),\n",
       "   ('405', 0.052799270516859634),\n",
       "   ('132', 0.046356566864634102),\n",
       "   ('578', 0.038102212715093828),\n",
       "   ('473', 0.032214229450347236),\n",
       "   ('434', 0.029779082802830419),\n",
       "   ('247', 0.028101360357825303),\n",
       "   ('1300', 0.026441439466019113)]),\n",
       " (20,\n",
       "  [('212', 0.043991370250776082),\n",
       "   ('949', 0.041780605125565175),\n",
       "   ('150', 0.0352653842498643),\n",
       "   ('386', 0.034646633859531879),\n",
       "   ('153', 0.031884377569569029),\n",
       "   ('56', 0.031803769002536009),\n",
       "   ('177', 0.029756053065311941),\n",
       "   ('1081', 0.025379689895871613),\n",
       "   ('223', 0.025335208152624428),\n",
       "   ('1000', 0.023862186918150539)]),\n",
       " (21,\n",
       "  [('681', 0.11640332568244377),\n",
       "   ('328', 0.10706265479411337),\n",
       "   ('16', 0.067166318595237084),\n",
       "   ('437', 0.060331028757312444),\n",
       "   ('25', 0.055043373709271051),\n",
       "   ('1004', 0.042111148412366621),\n",
       "   ('490', 0.039634875785878522),\n",
       "   ('1107', 0.037646860212467291),\n",
       "   ('502', 0.035496123096479613),\n",
       "   ('1400', 0.031200914254888967)]),\n",
       " (22,\n",
       "  [('1125', 0.079666106233620498),\n",
       "   ('1242', 0.053874361311095055),\n",
       "   ('415', 0.053581399591004608),\n",
       "   ('86', 0.04767666800158088),\n",
       "   ('70', 0.032195728798238232),\n",
       "   ('579', 0.02802357867843806),\n",
       "   ('969', 0.026366207094139445),\n",
       "   ('757', 0.024739932878896843),\n",
       "   ('797', 0.024250997391988639),\n",
       "   ('1837', 0.023994981899309376)]),\n",
       " (23,\n",
       "  [('37', 0.18590259676259419),\n",
       "   ('376', 0.092396860942664388),\n",
       "   ('232', 0.050843831695975929),\n",
       "   ('89', 0.040348907919114801),\n",
       "   ('1874', 0.038844295144291045),\n",
       "   ('1170', 0.038060844779090879),\n",
       "   ('822', 0.028640742093208448),\n",
       "   ('25', 0.028356509516377693),\n",
       "   ('274', 0.027525424760357027),\n",
       "   ('1099', 0.027435155618422608)]),\n",
       " (24,\n",
       "  [('48', 0.082453218520814123),\n",
       "   ('302', 0.072329870172957264),\n",
       "   ('1078', 0.057250463780346782),\n",
       "   ('774', 0.053546189662835808),\n",
       "   ('446', 0.04972179931298535),\n",
       "   ('524', 0.049390725220929063),\n",
       "   ('1348', 0.03286020336946778),\n",
       "   ('1218', 0.029905571050704398),\n",
       "   ('29', 0.028949545123101984),\n",
       "   ('2028', 0.028938175672233453)]),\n",
       " (25,\n",
       "  [('17', 0.065871753443313946),\n",
       "   ('276', 0.062784252638674695),\n",
       "   ('45', 0.054114490241465418),\n",
       "   ('346', 0.044684336544209564),\n",
       "   ('44', 0.041087806617558252),\n",
       "   ('22', 0.040652071900723667),\n",
       "   ('645', 0.040140537637780832),\n",
       "   ('33', 0.031494442303467242),\n",
       "   ('19', 0.031275683612755095),\n",
       "   ('41', 0.028312119851508531)]),\n",
       " (26,\n",
       "  [('223', 0.08420864192503888),\n",
       "   ('57', 0.046084312302042539),\n",
       "   ('48', 0.041848864506921463),\n",
       "   ('4', 0.036764958396804027),\n",
       "   ('108', 0.035671568932308273),\n",
       "   ('9', 0.035486682652469466),\n",
       "   ('43', 0.03379928029178908),\n",
       "   ('29', 0.030368191568573198),\n",
       "   ('343', 0.030267956649511457),\n",
       "   ('125', 0.027278543818785233)]),\n",
       " (27,\n",
       "  [('190', 0.10281313277605161),\n",
       "   ('396', 0.056023143719680403),\n",
       "   ('17', 0.055852693884866161),\n",
       "   ('394', 0.045719203650082821),\n",
       "   ('54', 0.043353303369085834),\n",
       "   ('758', 0.038497923750263757),\n",
       "   ('861', 0.037084913718776188),\n",
       "   ('262', 0.035547862325468964),\n",
       "   ('21', 0.032079773850890073),\n",
       "   ('134', 0.03118127368906088)]),\n",
       " (28,\n",
       "  [('210', 0.19921560106740416),\n",
       "   ('68', 0.056731929515849586),\n",
       "   ('938', 0.055199861626734965),\n",
       "   ('362', 0.034041225114900868),\n",
       "   ('342', 0.033342232538592489),\n",
       "   ('182', 0.032698858945611663),\n",
       "   ('516', 0.032239892816296779),\n",
       "   ('427', 0.031090906246052017),\n",
       "   ('395', 0.028473920185160498),\n",
       "   ('1060', 0.0247081063546256)]),\n",
       " (29,\n",
       "  [('84', 0.13370062600240279),\n",
       "   ('475', 0.082420861230125889),\n",
       "   ('43', 0.047723143819926914),\n",
       "   ('898', 0.041587891954967794),\n",
       "   ('54', 0.03385649728473298),\n",
       "   ('1209', 0.032934209580945596),\n",
       "   ('21', 0.027348052639168351),\n",
       "   ('55', 0.025859993446401639),\n",
       "   ('1704', 0.025701974236252399),\n",
       "   ('865', 0.024006902993904757)]),\n",
       " (30,\n",
       "  [('204', 0.089062231258919419),\n",
       "   ('312', 0.087749122814195252),\n",
       "   ('48', 0.066706636124197236),\n",
       "   ('17', 0.05748755861657566),\n",
       "   ('117', 0.054236899435070235),\n",
       "   ('191', 0.050370914632283124),\n",
       "   ('459', 0.038227090700873829),\n",
       "   ('53', 0.033379734684661419),\n",
       "   ('439', 0.032895473701459323),\n",
       "   ('365', 0.029049410950041505)]),\n",
       " (31,\n",
       "  [('17', 0.071339350801741058),\n",
       "   ('206', 0.063071473248333787),\n",
       "   ('29', 0.052144710591120913),\n",
       "   ('308', 0.052130563741673144),\n",
       "   ('501', 0.045768566719169818),\n",
       "   ('97', 0.031759341206338679),\n",
       "   ('234', 0.031215682847699142),\n",
       "   ('1276', 0.031113719683935146),\n",
       "   ('279', 0.030216000571252795),\n",
       "   ('477', 0.028476312336976312)]),\n",
       " (32,\n",
       "  [('29', 0.062877818151568093),\n",
       "   ('101', 0.059885257642065273),\n",
       "   ('171', 0.050299856797266257),\n",
       "   ('826', 0.048544649363033168),\n",
       "   ('334', 0.041418503772449489),\n",
       "   ('165', 0.035932093547977495),\n",
       "   ('254', 0.033622654691453181),\n",
       "   ('700', 0.031740243889248607),\n",
       "   ('482', 0.030882225395951143),\n",
       "   ('630', 0.029141558274488492)]),\n",
       " (33,\n",
       "  [('390', 0.13345457601766361),\n",
       "   ('179', 0.070321020054338823),\n",
       "   ('149', 0.066367003551096593),\n",
       "   ('1068', 0.062901103551315521),\n",
       "   ('164', 0.050702552990295947),\n",
       "   ('1311', 0.031336646581226445),\n",
       "   ('1314', 0.031093589359164665),\n",
       "   ('852', 0.028204513804840122),\n",
       "   ('1024', 0.019293813234375859),\n",
       "   ('1091', 0.018389991254781392)]),\n",
       " (34,\n",
       "  [('45', 0.089085707471460593),\n",
       "   ('17', 0.073919225951533829),\n",
       "   ('4', 0.059243801214696572),\n",
       "   ('54', 0.048618182336489228),\n",
       "   ('252', 0.041403856253007021),\n",
       "   ('12', 0.040927384955912596),\n",
       "   ('256', 0.037726916953243671),\n",
       "   ('0', 0.037275092357760199),\n",
       "   ('195', 0.036579406224027104),\n",
       "   ('733', 0.031641802885223558)]),\n",
       " (35,\n",
       "  [('26', 0.097333460210104458),\n",
       "   ('95', 0.051797356283510683),\n",
       "   ('48', 0.042182965449773187),\n",
       "   ('98', 0.041984278268559445),\n",
       "   ('4', 0.039126762140688942),\n",
       "   ('231', 0.035174153493348743),\n",
       "   ('94', 0.034526422388543053),\n",
       "   ('361', 0.034279495110043419),\n",
       "   ('17', 0.028955740531032937),\n",
       "   ('29', 0.028487727902946739)]),\n",
       " (36,\n",
       "  [('203', 0.10850055118031687),\n",
       "   ('656', 0.064459690669521785),\n",
       "   ('1222', 0.060875479422394428),\n",
       "   ('174', 0.05785705153369422),\n",
       "   ('280', 0.043411401321535391),\n",
       "   ('933', 0.040932366001012584),\n",
       "   ('148', 0.040240696971079085),\n",
       "   ('566', 0.038537740457462215),\n",
       "   ('1228', 0.037499554691035129),\n",
       "   ('740', 0.033584279538834236)]),\n",
       " (37,\n",
       "  [('144', 0.17999160062170191),\n",
       "   ('140', 0.10057712507317246),\n",
       "   ('45', 0.061890531149927513),\n",
       "   ('91', 0.053363655286096483),\n",
       "   ('4', 0.053173533714141595),\n",
       "   ('0', 0.040642865177376898),\n",
       "   ('1049', 0.03794624022309441),\n",
       "   ('17', 0.034784082726492846),\n",
       "   ('54', 0.033766631399447022),\n",
       "   ('32', 0.0250320330123384)]),\n",
       " (38,\n",
       "  [('54', 0.063505123706221162),\n",
       "   ('489', 0.060345068935401036),\n",
       "   ('17', 0.054207015287186182),\n",
       "   ('712', 0.045452526393074011),\n",
       "   ('4', 0.040618271781896094),\n",
       "   ('552', 0.040307700322139123),\n",
       "   ('79', 0.036865114941628689),\n",
       "   ('0', 0.030579913039912927),\n",
       "   ('12', 0.029771155477254358),\n",
       "   ('19', 0.029571536712105117)]),\n",
       " (39,\n",
       "  [('81', 0.10058287392851888),\n",
       "   ('146', 0.066165172933974017),\n",
       "   ('73', 0.062742696003273632),\n",
       "   ('78', 0.058468985000598515),\n",
       "   ('100', 0.053626273422525537),\n",
       "   ('668', 0.034495694785873665),\n",
       "   ('729', 0.030200642640448919),\n",
       "   ('9', 0.029459568934012297),\n",
       "   ('277', 0.027665437336932015),\n",
       "   ('34', 0.025502752658135543)])]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "159\n",
      "51\n",
      "62\n",
      "6\n",
      "5\n",
      "39\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "cnt = Counter()\n",
    "for t in topics:\n",
    "    for x in t[1]:\n",
    "        for ing in texts[int(x[0])]:\n",
    "            cnt[ing] += 1\n",
    "\n",
    "for key in \"salt\", \"sugar\", \"water\", \"mushrooms\", \"chicken\", \"eggs\":\n",
    "    print cnt[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_answers1(c_salt, c_sugar, c_water, c_mushrooms, c_chicken, c_eggs):\n",
    "    with open(\"cooking_LDA_pa_task1.txt\", \"w\") as fout:\n",
    "        fout.write(\" \".join([str(el) for el in [c_salt, c_sugar, c_water, c_mushrooms, c_chicken, c_eggs]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "save_answers1(*[cnt[key] for key in \"salt\", \"sugar\", \"water\", \"mushrooms\", \"chicken\", \"eggs\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Фильтрация словаря\n",
    "В топах тем гораздо чаще встречаются первые три рассмотренных ингредиента, чем последние три. При этом наличие в рецепте курицы, яиц и грибов яснее дает понять, что мы будем готовить, чем наличие соли, сахара и воды. Таким образом, даже в рецептах есть слова, часто встречающиеся в текстах и не несущие смысловой нагрузки, и поэтому их не желательно видеть в темах. Наиболее простой прием борьбы с такими фоновыми элементами - фильтрация словаря по частоте. Обычно словарь фильтруют с двух сторон: убирают очень редкие слова (в целях экономии памяти) и очень частые слова (в целях повышения интерпретируемости тем). Мы уберем только частые слова."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "dictionary2 = copy.deepcopy(dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Задание 2.__ У объекта dictionary2 есть переменная dfs - это словарь, ключами которого являются id токена, а элементами - число раз, сколько слово встретилось во всей коллекции. Сохраните в отдельный список ингредиенты, которые встретились в коллекции больше 4000 раз. Вызовите метод словаря filter_tokens, подав в качестве первого аргумента полученный список популярных ингредиентов. Вычислите две величины: dict_size_before и dict_size_after - размер словаря до и после фильтрации.\n",
    "\n",
    "Затем, используя новый словарь, создайте новый корпус документов, corpus2, по аналогии с тем, как это сделано в начале ноутбука. Вычислите две величины: corpus_size_before и corpus_size_after - суммарное количество ингредиентов в корпусе (иными словами, сумма длин всех документов коллекции) до и после фильтрации.\n",
    "\n",
    "Передайте величины dict_size_before, dict_size_after, corpus_size_before, corpus_size_after в функцию save_answers2 и загрузите сгенерированный файл в форму."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_answers2(dict_size_before, dict_size_after, corpus_size_before, corpus_size_after):\n",
    "    with open(\"cooking_LDA_pa_task2.txt\", \"w\") as fout:\n",
    "        fout.write(\" \".join([str(el) for el in [dict_size_before, dict_size_after, corpus_size_before, corpus_size_after]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сравнение когерентностей\n",
    "__Задание 3.__ Постройте еще одну модель по корпусу corpus2 и словарю dictioanary2, остальные параметры оставьте такими же, как при первом построении модели. Сохраните новую модель в другую переменную (не перезаписывайте предыдущую модель). Не забудьте про фиксирование seed!\n",
    "\n",
    "Затем воспользуйтесь методом top_topics модели, чтобы вычислить ее когерентность. Передайте в качестве аргумента соответствующий модели корпус. Метод вернет список кортежей (топ токенов, когерентность), отсортированных по убыванию последней. Вычислите среднюю по всем темам когерентность для каждой из двух моделей и передайте в функцию save_answers3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_answers3(coherence, coherence2):\n",
    "    with open(\"cooking_LDA_pa_task3.txt\", \"w\") as fout:\n",
    "        fout.write(\" \".join([\"%3f\"%el for el in [coherence, coherence2]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Считается, что когерентность хорошо соотносится с человеческими оценками интерпретируемости тем. Поэтому на больших текстовых коллекциях когерентность обычно повышается, если убрать фоновую лексику. Однако в нашем случае этого не произошло. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Изучение влияния гиперпараметра alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом разделе мы будем работать со второй моделью, то есть той, которая построена по сокращенному корпусу. \n",
    "\n",
    "Пока что мы посмотрели только на матрицу темы-слова, теперь давайте посмотрим на матрицу темы-документы. Выведите темы для нулевого (или любого другого) документа из корпуса, воспользовавшись методом get_document_topics второй модели:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также выведите содержимое переменной .alpha второй модели:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У вас должно получиться, что документ характеризуется небольшим числом тем. Попробуем поменять гиперпараметр alpha, задающий априорное распределение Дирихле для распределений тем в документах."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Задание 4.__ Обучите третью модель: используйте сокращенный корпус (corpus2 и dictionary2) и установите параметр __alpha=1__, passes=5. Не забудьте задать количество тем и зафиксировать seed! Выведите темы новой модели для нулевого документа; должно получиться, что распределение над множеством тем практически равномерное. Чтобы убедиться в том, что во второй модели документы описываются гораздо более разреженными распределениями, чем в третьей, посчитайте суммарное количество элементов, __превосходящих 0.01__, в матрицах темы-документы обеих моделей. Другими словами, запросите темы  модели для каждого документа с параметром minimum_probability=0.01 и просуммируйте число элементов в получаемых массивах. Передайте две суммы (сначала для модели с alpha по умолчанию, затем для модели в alpha=1) в функцию save_answers4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_answers4(count_model2, count_model3):\n",
    "    with open(\"cooking_LDA_pa_task4.txt\", \"w\") as fout:\n",
    "        fout.write(\" \".join([str(el) for el in [count_model2, count_model3]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Таким образом, гиперпараметр alpha влияет на разреженность распределений тем в документах. Аналогично гиперпараметр eta влияет на разреженность распределений слов в темах."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA как способ понижения размерности\n",
    "Иногда распределения над темами, найденные с помощью LDA, добавляют в матрицу объекты-признаки как дополнительные, семантические, признаки, и это может улучшить качество решения задачи. Для простоты давайте просто обучим классификатор рецептов на кухни на признаках, полученных из LDA, и измерим точность (accuracy).\n",
    "\n",
    "__Задание 5.__ Используйте модель, построенную по сокращенной выборке с alpha по умолчанию (вторую модель). Составьте матрицу $\\Theta = p(t|d)$ вероятностей тем в документах; вы можете использовать тот же метод get_document_topics, а также вектор правильных ответов y (в том же порядке, в котором рецепты идут в переменной recipes). Создайте объект RandomForestClassifier со 100 деревьями, с помощью функции cross_val_score вычислите среднюю accuracy по трем фолдам (перемешивать данные не нужно) и передайте в функцию save_answers5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.cross_validation import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_answers5(accuracy):\n",
    "     with open(\"cooking_LDA_pa_task5.txt\", \"w\") as fout:\n",
    "        fout.write(str(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для такого большого количества классов это неплохая точность. Вы можете попроовать обучать RandomForest на исходной матрице частот слов, имеющей значительно большую размерность, и увидеть, что accuracy увеличивается на 10-15%. Таким образом, LDA собрал не всю, но достаточно большую часть информации из выборки, в матрице низкого ранга."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA --- вероятностная модель\n",
    "Матричное разложение, использующееся в LDA, интерпретируется как следующий процесс генерации документов.\n",
    "\n",
    "Для документа $d$ длины $n_d$:\n",
    "1. Из априорного распределения Дирихле с параметром alpha сгенерировать распределение над множеством тем: $\\theta_d \\sim Dirichlet(\\alpha)$\n",
    "1. Для каждого слова $w = 1, \\dots, n_d$:\n",
    "    1. Сгенерировать тему из дискретного распределения $t \\sim \\theta_{d}$\n",
    "    1. Сгенерировать слово из дискретного распределения $w \\sim \\phi_{t}$.\n",
    "    \n",
    "Подробнее об этом в [Википедии](https://en.wikipedia.org/wiki/Latent_Dirichlet_allocation).\n",
    "\n",
    "В контексте нашей задачи получается, что, используя данный генеративный процесс, можно создавать новые рецепты. Вы можете передать в функцию модель и число ингредиентов и сгенерировать рецепт :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generate_recipe(model, num_ingredients):\n",
    "    theta = np.random.dirichlet(model.alpha)\n",
    "    for i in range(num_ingredients):\n",
    "        t = np.random.choice(np.arange(model.num_topics), p=theta)\n",
    "        topic = model.show_topic(0, topn=model.num_terms)\n",
    "        topic_distr = [x[1] for x in topic]\n",
    "        terms = [x[0] for x in topic]\n",
    "        w = np.random.choice(terms, p=topic_distr)\n",
    "        print w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Интерпретация построенной модели\n",
    "Вы можете рассмотреть топы ингредиентов каждой темы. Большиснтво тем сами по себе похожи на рецепты; в некоторых собираются продукты одного вида, например, свежие фрукты или разные виды сыра.\n",
    "\n",
    "Попробуем эмпирически соотнести наши темы с национальными кухнями (cuisine). Построим матрицу A размера темы x кухни, ее элементы $a_{tc}$ - суммы p(t|d) по всем документам d, которые отнесены к кухне c. Нормируем матрицу на частоты рецептов по разным кухням, чтобы избежать дисбаланса между кухнями. Следующая функция получает на вход объект модели, объект корпуса и исходные данные и возвращает нормированную матрицу A. Ее удобно визуализировать с помощью seaborn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "import seaborn\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_topic_cuisine_matrix(model, corpus, recipes):\n",
    "    # составляем вектор целевых признаков\n",
    "    targets = list(set([recipe[\"cuisine\"] for recipe in recipes]))\n",
    "    # составляем матрицу\n",
    "    tc_matrix = pandas.DataFrame(data=np.zeros((model.num_topics, len(targets))), columns=targets)\n",
    "    for recipe, bow in zip(recipes, corpus):\n",
    "        recipe_topic = model.get_document_topics(bow)\n",
    "        for t, prob in recipe_topic:\n",
    "            tc_matrix[recipe[\"cuisine\"]][t] += prob\n",
    "    # нормируем матрицу\n",
    "    target_sums = pandas.DataFrame(data=np.zeros((1, len(targets))), columns=targets)\n",
    "    for recipe in recipes:\n",
    "        target_sums[recipe[\"cuisine\"]] += 1\n",
    "    return pandas.DataFrame(tc_matrix.values/target_sums.values, columns=tc_matrix.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_matrix(tc_matrix):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    seaborn.heatmap(tc_matrix, square=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Визуализируйте матрицу\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чем темнее квадрат в матрице, тем больше связь этой темы с данной кухней. Мы видим, что у нас есть темы, которые связаны с несколькими кухнями. Такие темы показывают набор ингредиентов, которые популярны в кухнях нескольких народов, то есть указывают на схожесть кухонь этих народов. Некоторые темы распределены по всем кухням равномерно, они показывают наборы продуктов, которые часто используются в кулинарии всех стран. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Жаль, что в датасете нет названий рецептов, иначе темы было бы проще интерпретировать..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Заключение\n",
    "В этом задании вы построили несколько моделей LDA, посмотрели, на что влияют гиперпараметры модели и как можно использовать построенную модель. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
