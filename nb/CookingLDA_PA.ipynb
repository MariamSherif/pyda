{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Programming Assignment\n",
    "## Готовим LDA по рецептам"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как вы уже знаете, в тематическом моделировании делается предположение о том, что для определения тематики порядок слов в документе не важен; об этом гласит гипотеза <<мешка слов>>. Сегодня мы будем работать с несколько нестандартной для тематического моделирования коллекцией, которую можно назвать <<мешком ингредиентов>>, потому что на состоит из рецептов блюд разных кухонь. Тематические модели ищут слова, которые часто вместе встречаются в документах, и составляют из них темы. Мы попробуем применить эту идею к рецептам и найти кулинарные <<темы>>. Эта коллекция хороша тем, что не требует предобработки. Кроме того, эта задача достаточно наглядно иллюстрирует принцип работы тематических моделей.\n",
    "\n",
    "Для выполнения заданий, помимо часто используемых в курсе библиотек, потребуются модули json и gensim. Первый входит в дистрибутив Anaconda, второй можно поставить командой \n",
    "\n",
    "pip install gensim\n",
    "\n",
    "или\n",
    "\n",
    "conda install gensim\n",
    "\n",
    "Построение модели занимает некоторое время. На ноутбуке с процессором Intel Core i7 и тактовой частотой 2400 МГц на построение одной модели уходит менее 10 минут."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загрузка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Коллекция дана в json-формате: для каждого рецепта известны его id, кухня (\"cuisine\") и список ингредиентов, в него входящих. Загрузить данные можно с помощью модуля json (он входит в дистрибутив Anaconda):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"recipes.json\") as f:\n",
    "    recipes = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'cuisine': u'greek', u'id': 10259, u'ingredients': [u'romaine lettuce', u'black olives', u'grape tomatoes', u'garlic', u'pepper', u'purple onion', u'seasoning', u'garbanzo beans', u'feta cheese crumbles']}\n"
     ]
    }
   ],
   "source": [
    "print recipes[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Составление корпуса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from gensim import corpora, models\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наша коллекция небольшая и влезает в оперативную память. Gensim может работать с такими данными и не требует их сохранения на диск в специальном формате. Для этого коллекция должна быть представлена в виде списка списков, каждый внутренний список соответствует отдельному документу и состоит из его слов. Пример коллекции из двух документов: \n",
    "\n",
    "[[\"hello\", \"world\"], [\"programming\", \"in\", \"python\"]]\n",
    "\n",
    "Преобразуем наши данные в такой формат, а затем создадим объекты corpus и dictionary, с которыми будет работать модель."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "texts = [recipe[\"ingredients\"] for recipe in recipes]\n",
    "dictionary = corpora.Dictionary(texts)   # составляем словарь\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]  # составляем корпус документов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'romaine lettuce', u'black olives', u'grape tomatoes', u'garlic', u'pepper', u'purple onion', u'seasoning', u'garbanzo beans', u'feta cheese crumbles']\n",
      "[(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1), (6, 1), (7, 1), (8, 1)]\n"
     ]
    }
   ],
   "source": [
    "print texts[0]\n",
    "print corpus[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У объекта dictionary есть две полезных переменных: dictionary.id2token и dictionary.token2id; эти словари позволяют находить соответствие между ингредиентами и их индексами."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучение модели\n",
    "Вам может понадобиться [документация](https://radimrehurek.com/gensim/models/ldamodel.html) LDA в gensim."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Задание 1.__ Обучите модель LDA с 40 темами, установив количество проходов по коллекции 5 и оставив остальные параметры по умолчанию. Затем вызовите метод модели show_topics, указав количество тем 40 и количество токенов 10, и сохраните результат (топы ингредиентов в темах) в отдельную переменную. Если при вызове метода show_topics указать параметр formatted=True, то топы ингредиентов будет удобно выводить на печать, если formatted=False, будет удобно работать со списком программно. Выведите топы на печать, рассмотрите темы, а затем ответьте на вопрос:\n",
    "\n",
    "Сколько раз ингредиенты \"salt\", \"sugar\", \"water\", \"mushrooms\", \"chicken\", \"eggs\" встретились среди топов-10 всех 40 тем? При ответе __не нужно__ учитывать составные ингредиенты, например, \"hot water\".\n",
    "\n",
    "Передайте 6 чисел в функцию save_answers1 и загрузите сгенерированный файл в форму.\n",
    "\n",
    "У gensim нет возможности фиксировать случайное приближение через параметры метода, но библиотека использует numpy для инициализации матриц. Поэтому, по утверждению автора библиотеки, фиксировать случайное приближение нужно командой, которая написана в следующей ячейке. __Перед строкой кода с построением модели обязательно вставляйте указанную строку фиксации random.seed.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:gensim.models.ldamodel:no word id mapping provided; initializing from corpus, assuming identity\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(76543)\n",
    "# здесь код для построения модели:\n",
    "lda = models.LdaModel(corpus, num_topics=40, eval_every=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "topics = lda.show_topics(num_topics=40, num_words=10, formatted=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  [('100', 0.068936071835619853),\n",
       "   ('279', 0.060817929685598127),\n",
       "   ('54', 0.059481226580617191),\n",
       "   ('17', 0.056632592688071276),\n",
       "   ('119', 0.04061162889629924),\n",
       "   ('116', 0.040097524698285827),\n",
       "   ('29', 0.031607004635396896),\n",
       "   ('38', 0.024130520676101202),\n",
       "   ('555', 0.023739388880594032),\n",
       "   ('358', 0.023517282354035916)]),\n",
       " (1,\n",
       "  [('195', 0.070070912860140958),\n",
       "   ('45', 0.048345574834476504),\n",
       "   ('178', 0.043232910781952155),\n",
       "   ('958', 0.033871080766830285),\n",
       "   ('17', 0.031637280374493433),\n",
       "   ('29', 0.030532282368597136),\n",
       "   ('231', 0.03052119812679507),\n",
       "   ('26', 0.029670963682694368),\n",
       "   ('124', 0.028165483513344081),\n",
       "   ('4', 0.027305473244157025)]),\n",
       " (2,\n",
       "  [('770', 0.050973282228643474),\n",
       "   ('350', 0.050720990193965698),\n",
       "   ('830', 0.036477823774160471),\n",
       "   ('3', 0.033649601324912848),\n",
       "   ('17', 0.032789109718193064),\n",
       "   ('1338', 0.029711645863966525),\n",
       "   ('1637', 0.026684493890497971),\n",
       "   ('806', 0.025559108851097787),\n",
       "   ('816', 0.025012581689292261),\n",
       "   ('480', 0.024715924323523417)]),\n",
       " (3,\n",
       "  [('41', 0.1051374396799845),\n",
       "   ('207', 0.09685175264186191),\n",
       "   ('352', 0.053990068442235181),\n",
       "   ('383', 0.050519603177230504),\n",
       "   ('425', 0.044560029101421601),\n",
       "   ('17', 0.035554259153231384),\n",
       "   ('45', 0.035000479011008959),\n",
       "   ('397', 0.031367816412702129),\n",
       "   ('77', 0.028385953158420064),\n",
       "   ('792', 0.022685110526105941)]),\n",
       " (4,\n",
       "  [('17', 0.057235476471372893),\n",
       "   ('20', 0.0540092223630654),\n",
       "   ('200', 0.043964910691454043),\n",
       "   ('45', 0.040652224717698582),\n",
       "   ('39', 0.038065378533178193),\n",
       "   ('348', 0.03503870673615863),\n",
       "   ('183', 0.031696464762681391),\n",
       "   ('0', 0.025740016077613531),\n",
       "   ('216', 0.025350188673366244),\n",
       "   ('236', 0.024713505854090351)]),\n",
       " (5,\n",
       "  [('46', 0.0632949008483467),\n",
       "   ('17', 0.053157876327254321),\n",
       "   ('113', 0.045130085351889448),\n",
       "   ('54', 0.040228002043979416),\n",
       "   ('45', 0.037569473983061957),\n",
       "   ('4', 0.032410794966293337),\n",
       "   ('183', 0.029013083274686723),\n",
       "   ('127', 0.024938075854376046),\n",
       "   ('100', 0.021853922644222742),\n",
       "   ('39', 0.02059970121155574)]),\n",
       " (6,\n",
       "  [('51', 0.10039956310407416),\n",
       "   ('366', 0.07834845491414634),\n",
       "   ('387', 0.05347791073399228),\n",
       "   ('541', 0.041522278159379859),\n",
       "   ('52', 0.032041207112121162),\n",
       "   ('249', 0.031953749827698906),\n",
       "   ('511', 0.029034461449591698),\n",
       "   ('17', 0.026819734513081898),\n",
       "   ('701', 0.022702736976507331),\n",
       "   ('373', 0.021938285620079954)]),\n",
       " (7,\n",
       "  [('112', 0.0830954727309208),\n",
       "   ('557', 0.071026057267507214),\n",
       "   ('76', 0.058966210041987412),\n",
       "   ('54', 0.058359463831337915),\n",
       "   ('17', 0.045799727063739491),\n",
       "   ('193', 0.028349781983792229),\n",
       "   ('504', 0.026251078842110451),\n",
       "   ('0', 0.023118009074376632),\n",
       "   ('190', 0.02264358498551081),\n",
       "   ('322', 0.021875956571572961)]),\n",
       " (8,\n",
       "  [('17', 0.066719559952369251),\n",
       "   ('23', 0.061087254215609545),\n",
       "   ('29', 0.054875764126846638),\n",
       "   ('155', 0.053150457596139684),\n",
       "   ('471', 0.04259032324441437),\n",
       "   ('456', 0.04185168683173935),\n",
       "   ('1286', 0.03088194815557797),\n",
       "   ('1090', 0.026667204794009226),\n",
       "   ('352', 0.026551658826096391),\n",
       "   ('45', 0.026233438153236661)]),\n",
       " (9,\n",
       "  [('45', 0.064211878714879461),\n",
       "   ('478', 0.059776172032864644),\n",
       "   ('321', 0.059642028825089781),\n",
       "   ('4', 0.048644768791434236),\n",
       "   ('83', 0.046407119112793729),\n",
       "   ('17', 0.037957828619092332),\n",
       "   ('33', 0.034347279771337516),\n",
       "   ('186', 0.03313366325332337),\n",
       "   ('245', 0.028151974715000284),\n",
       "   ('345', 0.02672610270865116)]),\n",
       " (10,\n",
       "  [('12', 0.056124460727995804),\n",
       "   ('78', 0.040523013825448637),\n",
       "   ('17', 0.03638078966328246),\n",
       "   ('204', 0.029692174402732904),\n",
       "   ('313', 0.029273154513096363),\n",
       "   ('312', 0.028333527929169922),\n",
       "   ('990', 0.028291589692849183),\n",
       "   ('114', 0.024340522828276256),\n",
       "   ('21', 0.02364780048053795),\n",
       "   ('54', 0.023391532069099989)]),\n",
       " (11,\n",
       "  [('58', 0.064397216081112374),\n",
       "   ('17', 0.057729746668336211),\n",
       "   ('110', 0.049174807690476781),\n",
       "   ('74', 0.039989534415661242),\n",
       "   ('8', 0.034102949059586309),\n",
       "   ('839', 0.031533519576786725),\n",
       "   ('4', 0.031202439104744691),\n",
       "   ('54', 0.030336295991487516),\n",
       "   ('111', 0.02835951742649202),\n",
       "   ('73', 0.027566218291278064)]),\n",
       " (12,\n",
       "  [('536', 0.1176712583224991),\n",
       "   ('569', 0.056011547976903719),\n",
       "   ('1743', 0.038363628868277252),\n",
       "   ('1044', 0.037809432834557191),\n",
       "   ('876', 0.032617449723680747),\n",
       "   ('7', 0.029789633373466465),\n",
       "   ('1043', 0.02956295448681533),\n",
       "   ('600', 0.029337567600587072),\n",
       "   ('8', 0.026872451588544018),\n",
       "   ('564', 0.026185774515160572)]),\n",
       " (13,\n",
       "  [('272', 0.061924422087549481),\n",
       "   ('201', 0.048345881449992592),\n",
       "   ('246', 0.046302135642059025),\n",
       "   ('577', 0.045282264917432834),\n",
       "   ('33', 0.036435993681045435),\n",
       "   ('520', 0.03391463174085655),\n",
       "   ('231', 0.031534779169867411),\n",
       "   ('46', 0.028838689423348458),\n",
       "   ('45', 0.025856555984095794),\n",
       "   ('71', 0.022284669907993687)]),\n",
       " (14,\n",
       "  [('228', 0.076687300178909304),\n",
       "   ('128', 0.068928591920326063),\n",
       "   ('864', 0.055377453680926579),\n",
       "   ('431', 0.047775831909923634),\n",
       "   ('622', 0.037015436155243928),\n",
       "   ('819', 0.033419925027679459),\n",
       "   ('129', 0.025640905202675975),\n",
       "   ('29', 0.025182889229914941),\n",
       "   ('48', 0.024612406909218718),\n",
       "   ('367', 0.021171451530807725)]),\n",
       " (15,\n",
       "  [('191', 0.065808867343302033),\n",
       "   ('48', 0.046257900643315329),\n",
       "   ('318', 0.043409806056809649),\n",
       "   ('432', 0.041238844162245866),\n",
       "   ('496', 0.028762400571926895),\n",
       "   ('835', 0.028738728871045009),\n",
       "   ('385', 0.026515886050791207),\n",
       "   ('243', 0.025516393604462013),\n",
       "   ('1607', 0.025078896496417213),\n",
       "   ('756', 0.024282060615534732)]),\n",
       " (16,\n",
       "  [('79', 0.075402636086463914),\n",
       "   ('100', 0.060798663849879912),\n",
       "   ('54', 0.057545808795714207),\n",
       "   ('59', 0.038591423387288604),\n",
       "   ('17', 0.037844034503859182),\n",
       "   ('309', 0.033824859914096388),\n",
       "   ('250', 0.029026655967507128),\n",
       "   ('251', 0.028320607837615558),\n",
       "   ('106', 0.027184502941516388),\n",
       "   ('12', 0.025173773099079706)]),\n",
       " (17,\n",
       "  [('357', 0.08021327551788851),\n",
       "   ('4', 0.052519334432948497),\n",
       "   ('45', 0.044533869374588135),\n",
       "   ('17', 0.038090018378469453),\n",
       "   ('237', 0.034166389294008274),\n",
       "   ('0', 0.027183606122973773),\n",
       "   ('11', 0.025334573138529624),\n",
       "   ('242', 0.022902203267657989),\n",
       "   ('29', 0.02150230204471805),\n",
       "   ('678', 0.020798327119563035)]),\n",
       " (18,\n",
       "  [('17', 0.097444918474646092),\n",
       "   ('117', 0.090881524992505319),\n",
       "   ('13', 0.074330414139068449),\n",
       "   ('18', 0.074300396265990096),\n",
       "   ('21', 0.065956183806380714),\n",
       "   ('49', 0.058156107088609015),\n",
       "   ('48', 0.049342572739200383),\n",
       "   ('311', 0.033967547632663707),\n",
       "   ('63', 0.03303293179932585),\n",
       "   ('204', 0.030286303790086747)]),\n",
       " (19,\n",
       "  [('273', 0.10972285800413895),\n",
       "   ('556', 0.052413877920719526),\n",
       "   ('405', 0.043068806618079075),\n",
       "   ('17', 0.034354391022507168),\n",
       "   ('132', 0.033634747246359308),\n",
       "   ('45', 0.0313888170997602),\n",
       "   ('9', 0.028497678639089537),\n",
       "   ('578', 0.025653970131259349),\n",
       "   ('434', 0.022147481100991632),\n",
       "   ('247', 0.021790197305220031)]),\n",
       " (20,\n",
       "  [('223', 0.038798721270207774),\n",
       "   ('212', 0.03211012350806914),\n",
       "   ('150', 0.031667478156626273),\n",
       "   ('386', 0.027178979820838976),\n",
       "   ('153', 0.025152750622962638),\n",
       "   ('949', 0.025025549310946481),\n",
       "   ('231', 0.023844852620986238),\n",
       "   ('177', 0.023057879823381703),\n",
       "   ('48', 0.022412292631781929),\n",
       "   ('1081', 0.020184807490409212)]),\n",
       " (21,\n",
       "  [('328', 0.072232192005716303),\n",
       "   ('16', 0.047775422655284124),\n",
       "   ('25', 0.0429155587329976),\n",
       "   ('437', 0.040104039951020493),\n",
       "   ('490', 0.030292420017146084),\n",
       "   ('1004', 0.028032389613017558),\n",
       "   ('916', 0.026128594407227541),\n",
       "   ('502', 0.02594920829299641),\n",
       "   ('329', 0.024786694455168772),\n",
       "   ('146', 0.023463282732329477)]),\n",
       " (22,\n",
       "  [('244', 0.063567847441946268),\n",
       "   ('1125', 0.063072044389131263),\n",
       "   ('415', 0.046751506915693464),\n",
       "   ('86', 0.037231670854505385),\n",
       "   ('70', 0.025060424376010412),\n",
       "   ('579', 0.024276912256390261),\n",
       "   ('1242', 0.024078770251755817),\n",
       "   ('969', 0.022626487799649757),\n",
       "   ('757', 0.021808979380443166),\n",
       "   ('21', 0.021235861290054843)]),\n",
       " (23,\n",
       "  [('376', 0.08192404481354687),\n",
       "   ('232', 0.054361241701062733),\n",
       "   ('89', 0.049872010824700837),\n",
       "   ('1276', 0.045480865663162395),\n",
       "   ('1874', 0.041501014821337945),\n",
       "   ('1170', 0.037554518974308677),\n",
       "   ('822', 0.030618153264455081),\n",
       "   ('274', 0.029499773350934091),\n",
       "   ('82', 0.02764646288181323),\n",
       "   ('29', 0.023916758085728872)]),\n",
       " (24,\n",
       "  [('48', 0.08623007831046596),\n",
       "   ('302', 0.061230814178957267),\n",
       "   ('774', 0.053851803243594273),\n",
       "   ('1078', 0.051122592432111223),\n",
       "   ('524', 0.042146075763680298),\n",
       "   ('1348', 0.033259746016174964),\n",
       "   ('29', 0.031397812548294962),\n",
       "   ('1218', 0.030685483379565035),\n",
       "   ('2028', 0.030030632262721336),\n",
       "   ('2029', 0.024314059977035625)]),\n",
       " (25,\n",
       "  [('17', 0.06254244231092794),\n",
       "   ('276', 0.055030989580329134),\n",
       "   ('45', 0.048683388575645185),\n",
       "   ('346', 0.046366749075505531),\n",
       "   ('44', 0.042169545535248182),\n",
       "   ('645', 0.038355088853107074),\n",
       "   ('22', 0.03387331101376808),\n",
       "   ('19', 0.031260111317200648),\n",
       "   ('33', 0.030065164234034745),\n",
       "   ('29', 0.02651312284005379)]),\n",
       " (26,\n",
       "  [('57', 0.051885568377661867),\n",
       "   ('223', 0.046617718469034786),\n",
       "   ('108', 0.040477404642876552),\n",
       "   ('48', 0.040407921236448568),\n",
       "   ('9', 0.035447702639231943),\n",
       "   ('29', 0.029695762657416969),\n",
       "   ('4', 0.028226705722685427),\n",
       "   ('373', 0.025403833698587036),\n",
       "   ('125', 0.025316971488748376),\n",
       "   ('927', 0.024923118920512806)]),\n",
       " (27,\n",
       "  [('190', 0.089334878758485253),\n",
       "   ('396', 0.056328024702254571),\n",
       "   ('17', 0.054239977400534961),\n",
       "   ('394', 0.045827247665381966),\n",
       "   ('54', 0.041043488424931489),\n",
       "   ('861', 0.03734092570642935),\n",
       "   ('758', 0.035855804732716497),\n",
       "   ('117', 0.030051555815986508),\n",
       "   ('262', 0.029558472349683586),\n",
       "   ('21', 0.028842454971278592)]),\n",
       " (28,\n",
       "  [('210', 0.1087308182286803),\n",
       "   ('68', 0.048130400524669929),\n",
       "   ('938', 0.041113403126752997),\n",
       "   ('342', 0.03081638666829092),\n",
       "   ('182', 0.027759651143158287),\n",
       "   ('427', 0.027316107342997813),\n",
       "   ('362', 0.026523826419253816),\n",
       "   ('395', 0.025308068598550861),\n",
       "   ('516', 0.023318742253022291),\n",
       "   ('1060', 0.021189235653515839)]),\n",
       " (29,\n",
       "  [('84', 0.082253317064075862),\n",
       "   ('475', 0.072577744294206978),\n",
       "   ('54', 0.043397569278613088),\n",
       "   ('898', 0.037307529206757603),\n",
       "   ('1209', 0.029652890973636589),\n",
       "   ('21', 0.0243612676290236),\n",
       "   ('55', 0.023362443829813243),\n",
       "   ('1704', 0.023339176161440274),\n",
       "   ('865', 0.021019521916760587),\n",
       "   ('717', 0.020314130915238992)]),\n",
       " (30,\n",
       "  [('312', 0.08350145699126385),\n",
       "   ('48', 0.069373557614876749),\n",
       "   ('204', 0.068656287480542422),\n",
       "   ('17', 0.052259205077374637),\n",
       "   ('117', 0.046671632875088472),\n",
       "   ('459', 0.041696918210695551),\n",
       "   ('365', 0.033033358031165923),\n",
       "   ('53', 0.033012731880631072),\n",
       "   ('439', 0.028670657102867547),\n",
       "   ('191', 0.028490884778300175)]),\n",
       " (31,\n",
       "  [('17', 0.077334672116166556),\n",
       "   ('206', 0.057659876555663368),\n",
       "   ('29', 0.042208696962703893),\n",
       "   ('501', 0.039640466185633369),\n",
       "   ('279', 0.038956588990127473),\n",
       "   ('21', 0.02641301682022075),\n",
       "   ('100', 0.025336803417602846),\n",
       "   ('120', 0.024346965871894145),\n",
       "   ('477', 0.024052476393818075),\n",
       "   ('97', 0.023898754478165859)]),\n",
       " (32,\n",
       "  [('29', 0.060864985144308159),\n",
       "   ('101', 0.058998050136724683),\n",
       "   ('826', 0.046272401754610309),\n",
       "   ('334', 0.038656430037545521),\n",
       "   ('700', 0.033378403789640472),\n",
       "   ('254', 0.033217365523549695),\n",
       "   ('482', 0.03074668349843012),\n",
       "   ('630', 0.027611520280363643),\n",
       "   ('633', 0.027237974607069986),\n",
       "   ('484', 0.025449478959981151)]),\n",
       " (33,\n",
       "  [('390', 0.079959050717223673),\n",
       "   ('179', 0.060693985793737283),\n",
       "   ('1068', 0.054050323498742225),\n",
       "   ('164', 0.041727780983180113),\n",
       "   ('149', 0.035615981505871218),\n",
       "   ('1091', 0.030282944841216505),\n",
       "   ('1314', 0.028840780021166457),\n",
       "   ('1311', 0.027551443608036786),\n",
       "   ('137', 0.02467857866326529),\n",
       "   ('852', 0.024150621501426967)]),\n",
       " (34,\n",
       "  [('45', 0.064380804308121597),\n",
       "   ('252', 0.057168629281009041),\n",
       "   ('17', 0.048147481028917347),\n",
       "   ('4', 0.04662876528380204),\n",
       "   ('54', 0.042436667953485073),\n",
       "   ('12', 0.038578282345000645),\n",
       "   ('208', 0.034842137067617067),\n",
       "   ('315', 0.031389493499621203),\n",
       "   ('256', 0.030834845174044626),\n",
       "   ('319', 0.023498578488233991)]),\n",
       " (35,\n",
       "  [('26', 0.090023148759752966),\n",
       "   ('95', 0.049067714850514477),\n",
       "   ('98', 0.042229521477085731),\n",
       "   ('48', 0.040718729116997296),\n",
       "   ('4', 0.036327305480964141),\n",
       "   ('94', 0.034476699380205908),\n",
       "   ('361', 0.034373250178120318),\n",
       "   ('231', 0.030168804975236798),\n",
       "   ('352', 0.027386106919281384),\n",
       "   ('29', 0.026364630776455924)]),\n",
       " (36,\n",
       "  [('203', 0.070117284993177986),\n",
       "   ('534', 0.063779812376135545),\n",
       "   ('656', 0.054385873940488334),\n",
       "   ('174', 0.049058034174424163),\n",
       "   ('933', 0.033762121730679003),\n",
       "   ('148', 0.033707900206767283),\n",
       "   ('280', 0.032163041080529323),\n",
       "   ('1228', 0.031933159760941354),\n",
       "   ('566', 0.029601730985901683),\n",
       "   ('740', 0.028294640314302785)]),\n",
       " (37,\n",
       "  [('140', 0.098131572761055649),\n",
       "   ('144', 0.065633534568019042),\n",
       "   ('91', 0.061654866218529024),\n",
       "   ('4', 0.057632618628866872),\n",
       "   ('45', 0.054787634067300826),\n",
       "   ('54', 0.034364687622027219),\n",
       "   ('17', 0.028806753231960303),\n",
       "   ('0', 0.024920663334780737),\n",
       "   ('32', 0.024857259028696524),\n",
       "   ('1211', 0.021909082140593887)]),\n",
       " (38,\n",
       "  [('54', 0.066965948550020568),\n",
       "   ('17', 0.05854956403869073),\n",
       "   ('489', 0.055771859763197165),\n",
       "   ('4', 0.038452071548267887),\n",
       "   ('712', 0.03673243089584869),\n",
       "   ('0', 0.034835341987935899),\n",
       "   ('552', 0.030524849716022498),\n",
       "   ('12', 0.026008233346678275),\n",
       "   ('190', 0.024192318827365288),\n",
       "   ('79', 0.02409141701290337)]),\n",
       " (39,\n",
       "  [('81', 0.06541649514544072),\n",
       "   ('146', 0.049268248600007974),\n",
       "   ('78', 0.0457216223095099),\n",
       "   ('100', 0.042976655952584833),\n",
       "   ('277', 0.036850148908595698),\n",
       "   ('729', 0.03254648623178516),\n",
       "   ('34', 0.031979412165353979),\n",
       "   ('29', 0.022031420064742246),\n",
       "   ('73', 0.021481097386968791),\n",
       "   ('17', 0.020970014068751135)])]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "148\n",
      "49\n",
      "68\n",
      "5\n",
      "5\n",
      "42\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "cnt = Counter()\n",
    "for t in topics:\n",
    "    for x in t[1]:\n",
    "        for ing in texts[int(x[0])]:\n",
    "            cnt[ing] += 1\n",
    "\n",
    "for key in \"salt\", \"sugar\", \"water\", \"mushrooms\", \"chicken\", \"eggs\":\n",
    "    print cnt[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_answers1(c_salt, c_sugar, c_water, c_mushrooms, c_chicken, c_eggs):\n",
    "    with open(\"cooking_LDA_pa_task1.txt\", \"w\") as fout:\n",
    "        fout.write(\" \".join([str(el) for el in [c_salt, c_sugar, c_water, c_mushrooms, c_chicken, c_eggs]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "save_answers1(*[cnt[key] for key in \"salt\", \"sugar\", \"water\", \"mushrooms\", \"chicken\", \"eggs\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Фильтрация словаря\n",
    "В топах тем гораздо чаще встречаются первые три рассмотренных ингредиента, чем последние три. При этом наличие в рецепте курицы, яиц и грибов яснее дает понять, что мы будем готовить, чем наличие соли, сахара и воды. Таким образом, даже в рецептах есть слова, часто встречающиеся в текстах и не несущие смысловой нагрузки, и поэтому их не желательно видеть в темах. Наиболее простой прием борьбы с такими фоновыми элементами - фильтрация словаря по частоте. Обычно словарь фильтруют с двух сторон: убирают очень редкие слова (в целях экономии памяти) и очень частые слова (в целях повышения интерпретируемости тем). Мы уберем только частые слова."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "dictionary2 = copy.deepcopy(dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Задание 2.__ У объекта dictionary2 есть переменная dfs - это словарь, ключами которого являются id токена, а элементами - число раз, сколько слово встретилось во всей коллекции. Сохраните в отдельный список ингредиенты, которые встретились в коллекции больше 4000 раз. Вызовите метод словаря filter_tokens, подав в качестве первого аргумента полученный список популярных ингредиентов. Вычислите две величины: dict_size_before и dict_size_after - размер словаря до и после фильтрации.\n",
    "\n",
    "Затем, используя новый словарь, создайте новый корпус документов, corpus2, по аналогии с тем, как это сделано в начале ноутбука. Вычислите две величины: corpus_size_before и corpus_size_after - суммарное количество ингредиентов в корпусе (иными словами, сумма длин всех документов коллекции) до и после фильтрации.\n",
    "\n",
    "Передайте величины dict_size_before, dict_size_after, corpus_size_before, corpus_size_after в функцию save_answers2 и загрузите сгенерированный файл в форму."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_answers2(dict_size_before, dict_size_after, corpus_size_before, corpus_size_after):\n",
    "    with open(\"cooking_LDA_pa_task2.txt\", \"w\") as fout:\n",
    "        fout.write(\" \".join([str(el) for el in [dict_size_before, dict_size_after, corpus_size_before, corpus_size_after]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сравнение когерентностей\n",
    "__Задание 3.__ Постройте еще одну модель по корпусу corpus2 и словарю dictioanary2, остальные параметры оставьте такими же, как при первом построении модели. Сохраните новую модель в другую переменную (не перезаписывайте предыдущую модель). Не забудьте про фиксирование seed!\n",
    "\n",
    "Затем воспользуйтесь методом top_topics модели, чтобы вычислить ее когерентность. Передайте в качестве аргумента соответствующий модели корпус. Метод вернет список кортежей (топ токенов, когерентность), отсортированных по убыванию последней. Вычислите среднюю по всем темам когерентность для каждой из двух моделей и передайте в функцию save_answers3. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_answers3(coherence, coherence2):\n",
    "    with open(\"cooking_LDA_pa_task3.txt\", \"w\") as fout:\n",
    "        fout.write(\" \".join([\"%3f\"%el for el in [coherence, coherence2]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Считается, что когерентность хорошо соотносится с человеческими оценками интерпретируемости тем. Поэтому на больших текстовых коллекциях когерентность обычно повышается, если убрать фоновую лексику. Однако в нашем случае этого не произошло. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Изучение влияния гиперпараметра alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом разделе мы будем работать со второй моделью, то есть той, которая построена по сокращенному корпусу. \n",
    "\n",
    "Пока что мы посмотрели только на матрицу темы-слова, теперь давайте посмотрим на матрицу темы-документы. Выведите темы для нулевого (или любого другого) документа из корпуса, воспользовавшись методом get_document_topics второй модели:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также выведите содержимое переменной .alpha второй модели:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "У вас должно получиться, что документ характеризуется небольшим числом тем. Попробуем поменять гиперпараметр alpha, задающий априорное распределение Дирихле для распределений тем в документах."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Задание 4.__ Обучите третью модель: используйте сокращенный корпус (corpus2 и dictionary2) и установите параметр __alpha=1__, passes=5. Не забудьте задать количество тем и зафиксировать seed! Выведите темы новой модели для нулевого документа; должно получиться, что распределение над множеством тем практически равномерное. Чтобы убедиться в том, что во второй модели документы описываются гораздо более разреженными распределениями, чем в третьей, посчитайте суммарное количество элементов, __превосходящих 0.01__, в матрицах темы-документы обеих моделей. Другими словами, запросите темы  модели для каждого документа с параметром minimum_probability=0.01 и просуммируйте число элементов в получаемых массивах. Передайте две суммы (сначала для модели с alpha по умолчанию, затем для модели в alpha=1) в функцию save_answers4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_answers4(count_model2, count_model3):\n",
    "    with open(\"cooking_LDA_pa_task4.txt\", \"w\") as fout:\n",
    "        fout.write(\" \".join([str(el) for el in [count_model2, count_model3]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Таким образом, гиперпараметр alpha влияет на разреженность распределений тем в документах. Аналогично гиперпараметр eta влияет на разреженность распределений слов в темах."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA как способ понижения размерности\n",
    "Иногда распределения над темами, найденные с помощью LDA, добавляют в матрицу объекты-признаки как дополнительные, семантические, признаки, и это может улучшить качество решения задачи. Для простоты давайте просто обучим классификатор рецептов на кухни на признаках, полученных из LDA, и измерим точность (accuracy).\n",
    "\n",
    "__Задание 5.__ Используйте модель, построенную по сокращенной выборке с alpha по умолчанию (вторую модель). Составьте матрицу $\\Theta = p(t|d)$ вероятностей тем в документах; вы можете использовать тот же метод get_document_topics, а также вектор правильных ответов y (в том же порядке, в котором рецепты идут в переменной recipes). Создайте объект RandomForestClassifier со 100 деревьями, с помощью функции cross_val_score вычислите среднюю accuracy по трем фолдам (перемешивать данные не нужно) и передайте в функцию save_answers5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.cross_validation import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_answers5(accuracy):\n",
    "     with open(\"cooking_LDA_pa_task5.txt\", \"w\") as fout:\n",
    "        fout.write(str(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для такого большого количества классов это неплохая точность. Вы можете попроовать обучать RandomForest на исходной матрице частот слов, имеющей значительно большую размерность, и увидеть, что accuracy увеличивается на 10-15%. Таким образом, LDA собрал не всю, но достаточно большую часть информации из выборки, в матрице низкого ранга."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA --- вероятностная модель\n",
    "Матричное разложение, использующееся в LDA, интерпретируется как следующий процесс генерации документов.\n",
    "\n",
    "Для документа $d$ длины $n_d$:\n",
    "1. Из априорного распределения Дирихле с параметром alpha сгенерировать распределение над множеством тем: $\\theta_d \\sim Dirichlet(\\alpha)$\n",
    "1. Для каждого слова $w = 1, \\dots, n_d$:\n",
    "    1. Сгенерировать тему из дискретного распределения $t \\sim \\theta_{d}$\n",
    "    1. Сгенерировать слово из дискретного распределения $w \\sim \\phi_{t}$.\n",
    "    \n",
    "Подробнее об этом в [Википедии](https://en.wikipedia.org/wiki/Latent_Dirichlet_allocation).\n",
    "\n",
    "В контексте нашей задачи получается, что, используя данный генеративный процесс, можно создавать новые рецепты. Вы можете передать в функцию модель и число ингредиентов и сгенерировать рецепт :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generate_recipe(model, num_ingredients):\n",
    "    theta = np.random.dirichlet(model.alpha)\n",
    "    for i in range(num_ingredients):\n",
    "        t = np.random.choice(np.arange(model.num_topics), p=theta)\n",
    "        topic = model.show_topic(0, topn=model.num_terms)\n",
    "        topic_distr = [x[1] for x in topic]\n",
    "        terms = [x[0] for x in topic]\n",
    "        w = np.random.choice(terms, p=topic_distr)\n",
    "        print w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Интерпретация построенной модели\n",
    "Вы можете рассмотреть топы ингредиентов каждой темы. Большиснтво тем сами по себе похожи на рецепты; в некоторых собираются продукты одного вида, например, свежие фрукты или разные виды сыра.\n",
    "\n",
    "Попробуем эмпирически соотнести наши темы с национальными кухнями (cuisine). Построим матрицу A размера темы x кухни, ее элементы $a_{tc}$ - суммы p(t|d) по всем документам d, которые отнесены к кухне c. Нормируем матрицу на частоты рецептов по разным кухням, чтобы избежать дисбаланса между кухнями. Следующая функция получает на вход объект модели, объект корпуса и исходные данные и возвращает нормированную матрицу A. Ее удобно визуализировать с помощью seaborn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "import seaborn\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_topic_cuisine_matrix(model, corpus, recipes):\n",
    "    # составляем вектор целевых признаков\n",
    "    targets = list(set([recipe[\"cuisine\"] for recipe in recipes]))\n",
    "    # составляем матрицу\n",
    "    tc_matrix = pandas.DataFrame(data=np.zeros((model.num_topics, len(targets))), columns=targets)\n",
    "    for recipe, bow in zip(recipes, corpus):\n",
    "        recipe_topic = model.get_document_topics(bow)\n",
    "        for t, prob in recipe_topic:\n",
    "            tc_matrix[recipe[\"cuisine\"]][t] += prob\n",
    "    # нормируем матрицу\n",
    "    target_sums = pandas.DataFrame(data=np.zeros((1, len(targets))), columns=targets)\n",
    "    for recipe in recipes:\n",
    "        target_sums[recipe[\"cuisine\"]] += 1\n",
    "    return pandas.DataFrame(tc_matrix.values/target_sums.values, columns=tc_matrix.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_matrix(tc_matrix):\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    seaborn.heatmap(tc_matrix, square=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Визуализируйте матрицу\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чем темнее квадрат в матрице, тем больше связь этой темы с данной кухней. Мы видим, что у нас есть темы, которые связаны с несколькими кухнями. Такие темы показывают набор ингредиентов, которые популярны в кухнях нескольких народов, то есть указывают на схожесть кухонь этих народов. Некоторые темы распределены по всем кухням равномерно, они показывают наборы продуктов, которые часто используются в кулинарии всех стран. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Жаль, что в датасете нет названий рецептов, иначе темы было бы проще интерпретировать..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Заключение\n",
    "В этом задании вы построили несколько моделей LDA, посмотрели, на что влияют гиперпараметры модели и как можно использовать построенную модель. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
